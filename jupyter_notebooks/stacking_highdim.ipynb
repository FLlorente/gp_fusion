{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/Users/fllorente/Dropbox/con_Petar/PYTHON/gp_fusion')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.data_handling import load_data, load_and_normalize_data\n",
    "from modules.model_training import train_and_predict_single_gp\n",
    "from modules.model_training import GPModel, to_torch\n",
    "from modules.fusion_methods import product_fusion\n",
    "from modules.fusion_methods import compute_neg_log_like\n",
    "\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from gpytorch.means import ZeroMean\n",
    "from gpytorch.kernels import AdditiveStructureKernel, RBFKernel, ScaleKernel\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.metrics import mean_standardized_log_loss\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input dim:  24\n",
      "training size:  143\n",
      "test size:  16\n"
     ]
    }
   ],
   "source": [
    "# ------------ Load and normalize data --------- #\n",
    "dataset_name = \"autos\"\n",
    "\n",
    "split=5\n",
    "X_train, y_train, X_test, y_test, y_std = load_data(dataset_name,split,)\n",
    "\n",
    "print('input dim: ', X_train.shape[1])\n",
    "print(\"training size: \", len(y_train))\n",
    "print(\"test size: \", len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.63930854e-05  2.37138165e-06  1.15270825e-05  1.29099445e-06\n",
      "  3.51763235e-06 -8.72081599e-06  6.12994837e-06  6.03475016e-06\n",
      " -5.31113006e-06 -4.72182186e-06  1.41440516e-05 -8.71014121e-06\n",
      "  4.29387139e-07  1.30303597e-06  6.78165922e-06  8.92713126e-06\n",
      " -1.77088659e-05 -1.33294018e-05  3.28627486e-06  7.92884062e-06\n",
      "  1.14154070e-05 -5.14751347e-06  1.80051111e-06 -8.41591323e-06]\n",
      "1.0397028718051562e-07\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# check that the entire dataset has zero mean (I didn't do this, but Trevor :-))\n",
    "print(np.mean(np.vstack([X_train,X_test]),axis=0))\n",
    "print(np.mean(np.concatenate([y_train,y_test]),axis=0))\n",
    "\n",
    "# I did normalize the intputs and outputs to have unit variance\n",
    "print(np.std(np.vstack([X_train,X_test]),axis=0))\n",
    "print(np.std(np.concatenate([y_train,y_test]),axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0174, dtype=torch.float64)\n",
      "[-0.01738962]\n"
     ]
    }
   ],
   "source": [
    "# Fit a GP with ARD-RBF kernel as the baseline\n",
    "\n",
    "test_preds, _ = train_and_predict_single_gp(X_train,y_train,X_test,X_test,\n",
    "                            kappa=2,lambdaa=2,\n",
    "                            mean=ZeroMean(),  # we don't want to use the mean of y_train as prior mean (using ConstantMean())\n",
    "                            lr=0.1,\n",
    "                            training_iter=100,\n",
    "                            initialiaze_hyper=True  # if false, kappa and lambdaa are not used for initializing the hyperparameter\n",
    "                            )\n",
    "\n",
    "# compute the negative log-likelihood (log-loss) on test data:\n",
    "print(mean_standardized_log_loss(test_preds, torch.from_numpy(y_test)))\n",
    "\n",
    "# equivalently:\n",
    "print(compute_neg_log_like(test_preds.mean.numpy(),\n",
    "                           np.sqrt(test_preds.variance).numpy(),\n",
    "                           y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.39663261]\n"
     ]
    }
   ],
   "source": [
    "# Let us do the check that we get the same results when we train and predict using the functions:\n",
    "# train_expert and predict_with_expert\n",
    "from modules.model_training import train_expert, predict_with_expert\n",
    "\n",
    "\n",
    "model,likelihood = train_expert(X_train,y_train,\n",
    "                                kappa=2,lambdaa=2,\n",
    "                                mean=ZeroMean(),\n",
    "                                lr=0.1,\n",
    "                                training_iter=500,\n",
    "                                initialize_hyper=False,\n",
    "                                )\n",
    "\n",
    "mean_preds,std_preds,_ = predict_with_expert(model,likelihood,X_test)\n",
    "\n",
    "print(compute_neg_log_like(mean_preds,std_preds,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's average results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  6.10it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nlpd = []\n",
    "rmse = []\n",
    "for i in tqdm(range(10)):\n",
    "    try:\n",
    "        X_train, y_train, X_test, y_test, y_std = load_data(dataset_name,i)\n",
    "\n",
    "        # # With load_and_normalize_data fun the data is normalized using the training data only\n",
    "        # X_train, y_train, X_test, y_test = load_and_normalize_data(dataset_name,i,\n",
    "        #                                                         normalize_y=True,  \n",
    "        #                                                         normalize_x_method=\"max-min\")\n",
    "\n",
    "        test_preds, _ = train_and_predict_single_gp(X_train,y_train,X_test,X_test,\n",
    "                                kappa=2,lambdaa=2,\n",
    "                                mean=ZeroMean(),  # we don't want to use the mean of y_train as prior mean\n",
    "                                lr=0.1,\n",
    "                                training_iter=100,\n",
    "                                initialiaze_hyper=False, # if false, kappa and lambdaa don't matter!\n",
    "                                )\n",
    "        nlpd_now = compute_neg_log_like(test_preds.mean,np.sqrt(test_preds.variance),y_test)\n",
    "\n",
    "        rmse_now = np.sqrt(np.mean((test_preds.mean.numpy() - y_test)**2))\n",
    "\n",
    "        nlpd.append(nlpd_now.squeeze())\n",
    "        rmse.append(rmse_now)\n",
    "    except:\n",
    "        print(\"There was an error during hyperparameter learning.\")\n",
    "\n",
    "\n",
    "nlpd = np.array(nlpd)\n",
    "rmse = np.array(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.50446794,  0.72029356,  0.05992493,  0.32965062,  0.11765238,\n",
       "       -0.02974258,  0.13023134,  0.1442318 ,  0.1408854 ,  0.37034965])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.248794504080366, 0.2181929104889972)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlpd.mean(),nlpd.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.35070544138449566, 0.13871238501254016)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse.mean(), rmse.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try using an additive kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:04<00:00,  2.37it/s]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "AdditiveStructureKernel computes d one-dimensional kernels (using the supplied base_kernel), \n",
    "and then adds the component kernels together.\n",
    "\"AdditiveStructureKernel is deprecated, and will be removed in GPyTorch 2.0. \"\n",
    "'Please refer to the \"Kernels with Additive or Product Structure\" tutorial '\n",
    "\"in the GPyTorch docs for how to implement GPs with additive structure.\"\n",
    "'''\n",
    "kernel = AdditiveStructureKernel(base_kernel=ScaleKernel(RBFKernel()), num_dims=X_train.shape[1])\n",
    "\n",
    "nlpd = []\n",
    "rmse = []\n",
    "for i in tqdm(range(10)):\n",
    "    # try:\n",
    "        X_train, y_train, X_test, y_test, y_std = load_data(dataset_name,i)\n",
    "\n",
    "        # # With load_and_normalize_data fun the data is normalized using the training data only\n",
    "        # X_train, y_train, X_test, y_test = load_and_normalize_data(dataset_name,i,\n",
    "        #                                                         normalize_y=True,  \n",
    "        #                                                         normalize_x_method=\"max-min\")\n",
    "\n",
    "        test_preds, _ = train_and_predict_single_gp(X_train,y_train,X_test,X_test,\n",
    "                                kappa=2,lambdaa=2,\n",
    "                                mean=ZeroMean(),  # we don't want to use the mean of y_train as prior mean\n",
    "                                kernel=kernel,\n",
    "                                lr=0.1,\n",
    "                                training_iter=100,\n",
    "                                initialiaze_hyper=False, # if False, kappa and lambdaa are not used for initializing the hyperparameters; we just use the default values.\n",
    "                                )\n",
    "        nlpd_now = compute_neg_log_like(test_preds.mean,np.sqrt(test_preds.variance),y_test)\n",
    "\n",
    "        rmse_now = np.sqrt(np.mean((test_preds.mean.detach().numpy() - y_test)**2))\n",
    "\n",
    "        nlpd.append(nlpd_now.squeeze())\n",
    "        rmse.append(rmse_now)\n",
    "    # except:\n",
    "    #     print(\"There was an error during hyperparameter learning.\")\n",
    "\n",
    "\n",
    "nlpd = np.array(nlpd)\n",
    "rmse = np.array(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.34137439, 0.6400602 , 0.37289921, 0.16129038, 0.13417607,\n",
       "       0.04016093, 0.02746184, 0.02168028, 0.0959663 , 0.19244998])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.20275195698146095, 0.18635589889484833)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlpd.mean(),nlpd.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3100164964961764, 0.08046684862617143)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse.mean(), rmse.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script true\n",
    "kernel = ScaleKernel(AdditiveStructureKernel(base_kernel=RBFKernel(), num_dims=X_train.shape[1]))\n",
    "model = GPModel(to_torch(X_train),\n",
    "                to_torch(y_train),\n",
    "                GaussianLikelihood(),\n",
    "                kernel=kernel,mean=ZeroMean())\n",
    "for name, param in model.named_parameters():\n",
    "    print(f'Parameter name: {name:42} value = {param.item():1.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stack GPs built on 1d projections:\n",
    "\n",
    "We'll use the axis-aligned 1d projections for the moment, since I think it's the one\n",
    "\"closer\" to using the additive kernel of one-dimensional kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:34<00:00,  3.42s/it]\n"
     ]
    }
   ],
   "source": [
    "nlpd = []\n",
    "rmse = []\n",
    "\n",
    "proj = \"axis\"\n",
    "\n",
    "for split in tqdm(range(10)):\n",
    "        X_train, y_train, X_test, y_test, y_std = load_data(dataset_name,split)\n",
    "\n",
    "        mean_experts = []\n",
    "        std_experts = []\n",
    "        for d in range(X_train.shape[1]):\n",
    "            if proj == \"random\":\n",
    "                  P_proj = np.random.rand(X_train.shape[1],1)\n",
    "            elif proj == \"axis\":\n",
    "                  index = d\n",
    "                  P_proj = np.array([1.0 if i == index else 0.0 for i in range(X_train.shape[1])])\n",
    "                  P_proj = P_proj.reshape(-1,1)\n",
    "\n",
    "            test_preds, _ = train_and_predict_single_gp(\n",
    "                                    np.matmul(X_train,P_proj),\n",
    "                                    y_train,\n",
    "                                    np.matmul(X_test,P_proj),\n",
    "                                    np.matmul(X_test,P_proj),\n",
    "                                    mean=ZeroMean(),  # we don't want to use the mean of y_train as prior mean\n",
    "                                    lr=0.1,\n",
    "                                    training_iter=100,\n",
    "                                    initialiaze_hyper=False, # if False, kappa and lambdaa are not used for initializing the hyperparameters; we just use the default values.\n",
    "                                    )\n",
    "            mean_experts.append(test_preds.mean.numpy())\n",
    "            std_experts.append(np.sqrt(test_preds.variance.numpy()))\n",
    "\n",
    "        mean_experts = np.stack(mean_experts,axis=-1)\n",
    "        std_experts = np.stack(std_experts,axis=-1)\n",
    "\n",
    "\n",
    "        # Fuse one-dimensional experts' predictions\n",
    "        mean_fused, std_fused, _ = product_fusion(mean_experts,std_experts,\n",
    "                                                  weighting=\"uniform\",\n",
    "                                                #   weighting=\"no-weights\",\n",
    "                                                #   normalize=False,\n",
    "                                                  method = \"gPoE\")\n",
    "        \n",
    "        nlpd_now = compute_neg_log_like(mean_fused,std_fused,y_test)\n",
    "        nlpd.append(nlpd_now.squeeze())\n",
    "\n",
    "        rmse_now = np.sqrt(np.mean( (mean_fused-y_test)**2 ))\n",
    "        rmse.append(rmse_now)\n",
    "        \n",
    "nlpd = np.array(nlpd)\n",
    "rmse = np.array(rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8012721086485826, 0.2046680391316493)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlpd.mean(), nlpd.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.1113879047936768, 0.23457900304804294)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse.mean(), rmse.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I want to try some of the models and training setups of Delbridge's repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/Users/fllorente/Dropbox/con_Petar/PYTHON/Randomly-Projected-Additive-GPs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fitting.optimizing import train_to_convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931,\n",
      "         0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931,\n",
      "         0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931]],\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([0.6932], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fllorente/Dropbox/con_Petar/PYTHON/Randomly-Projected-Additive-GPs/fitting/optimizing.py:81: RuntimeWarning: Mean of empty slice.\n",
      "  ma[i] = losses[i-patience+1:i+1].mean()\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "\n",
    "likelihood = GaussianLikelihood()\n",
    "model = GPModel(to_torch(X_train),to_torch(y_train),likelihood)\n",
    "\n",
    "print(model.covar_module.base_kernel.lengthscale)\n",
    "print(likelihood.noise_covar.noise)\n",
    "\n",
    "\n",
    "mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "max_iter = train_to_convergence(model, \n",
    "                     to_torch(X_train), \n",
    "                     to_torch(y_train),\n",
    "                     optimizer=torch.optim.Adam, objective=mll, \n",
    "                     max_iter=100, print_freq=1, verbose=0,lr = 0.1)\n",
    "max_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6.7088,  6.1273,  4.9083,  7.5706,  7.0607,  6.5998,  6.1216,  4.9640,\n",
      "          6.1993,  5.5571,  6.3582,  4.8340,  2.3613,  4.9477,  6.8069,  7.2692,\n",
      "          6.6578,  8.0215,  6.3105, 10.6027,  5.4907,  6.9049,  5.4511,  7.0181]],\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([0.0450], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(model.covar_module.base_kernel.lengthscale)\n",
    "print(likelihood.noise_covar.noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0292, grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_preds = likelihood(model(to_torch(X_test)))\n",
    "\n",
    "print(mean_standardized_log_loss(test_preds,to_torch(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to try now the function create_exact_gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training_routines import train_exact_gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fllorente/Dropbox/con_Petar/PYTHON/Randomly-Projected-Additive-GPs/fitting/optimizing.py:81: RuntimeWarning: Mean of empty slice.\n",
      "  ma[i] = losses[i-patience+1:i+1].mean()\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_args = {'ard': False, 'ski': False, 'grid_size': None, 'kernel_type': 'RBF', \n",
    "              'init_lengthscale_range': (0.1, 1.0), 'keops': False,\n",
    "              'noise_prior': False, 'init_noise_range': (0.1,1)\n",
    "              }\n",
    "train_args = {'lr': 0.1, 'max_iter': 100, 'verbose': 0, 'patience': 20,\n",
    "              'conv_tol': 1e-4, 'check_conv': True, 'smooth': True,\n",
    "              'batch_size': None, 'checkpoint': False, 'print_freq': 1,\n",
    "              'random_restarts': 5, 'optimizer': 'adam',\n",
    "              }\n",
    "\n",
    "model_metrics, pred_mean, model = train_exact_gp(trainX = to_torch(X_train), \n",
    "                                                 trainY = to_torch(y_train), \n",
    "                                                 testX = to_torch(X_test), \n",
    "                                                 testY = to_torch(y_test), \n",
    "                                                 kind = 'full', \n",
    "                                                 model_kwargs = model_args, \n",
    "                                                 train_kwargs = train_args,\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.40398284792900085, -0.1583402454853058)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_metrics[\"prior_train_nmll\"], model_metrics[\"train_nll\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(-0.1796, grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_standardized_log_loss(model.likelihood(model(to_torch(X_train))),\n",
    "                           to_torch(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02306675910949707\n",
      "0.02306676\n",
      "0.36906733155155\n",
      "0.36906815\n"
     ]
    }
   ],
   "source": [
    "print(model_metrics[\"test_nll\"]) # creo que esta mal calculado...\n",
    "'''\n",
    "esta usando mll = GaussianLogMarginalLikelihood para calcular este valor...\n",
    "por lo que estaria calculando la log-pdf de la Gaussian multivariate, en lugar de la\n",
    "media de las log-pdf de las Gaussianas univariantes.\n",
    "'''\n",
    "\n",
    "mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "mll.eval()\n",
    "aux =model(to_torch(X_test))\n",
    "print(-mll(aux,to_torch(y_test)).detach().numpy())\n",
    "\n",
    "\n",
    "# deberia ser igual a esto pero no...\n",
    "aux = model.likelihood(model(to_torch(X_test)))\n",
    "\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "print(\n",
    "    -multivariate_normal.logpdf(y_test, \n",
    "                           aux.mean.detach().numpy(),\n",
    "                           aux.covariance_matrix.detach().numpy(),\n",
    "                           )\n",
    ")\n",
    "\n",
    "# este valor coincide con\n",
    "print(-aux.log_prob(to_torch(y_test)).detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0133)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(mean_standardized_log_loss(model.likelihood(model(to_torch(X_test))),\n",
    "                           to_torch(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.9929,  0.9791,  0.0551, -0.3986, -0.5403, -0.3692, -0.3082, -0.4199,\n",
       "        -0.9787,  0.4410, -0.4687, -1.3667,  1.5264,  1.0115, -0.6052, -0.6271])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.9929,  0.9791,  0.0551, -0.3986, -0.5403, -0.3692, -0.3082, -0.4199,\n",
       "        -0.9787,  0.4410, -0.4687, -1.3667,  1.5264,  1.0115, -0.6052, -0.6271],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.likelihood(model(to_torch(X_test))).mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
