{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KeOps] Warning : omp.h header is not in the path, disabling OpenMP. To fix this, you can set the environment\n",
      "                  variable OMP_PATH to the location of the header before importing keopscore or pykeops,\n",
      "                  e.g. using os.environ: import os; os.environ['OMP_PATH'] = '/path/to/omp/header'\n",
      "[KeOps] Warning : Cuda libraries were not detected on the system or could not be loaded ; using cpu only mode\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append('/Users/fllorente/Dropbox/con_Petar/PYTHON/gp_fusion')\n",
    "from modules.model_training import train_and_predict_single_gp, GPModel, train_model, predict_with_expert, to_torch\n",
    "\n",
    "\n",
    "import torch\n",
    "import gpytorch\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.means import ConstantMean, ZeroMean\n",
    "from gpytorch.kernels import ScaleKernel, RBFKernel\n",
    "from gpytorch.metrics import negative_log_predictive_density, mean_squared_error, mean_standardized_log_loss\n",
    "\n",
    "from uci_datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gas dataset, N=2565, d=128\n"
     ]
    }
   ],
   "source": [
    "dataset_names = [\"autos\", 'housing','stock','sml',\n",
    "                 'elevators','breastcancer','forest','gas',\n",
    "                 ]\n",
    "\n",
    "\n",
    "dataset_name = dataset_names[7]\n",
    "full_dataset = Dataset(dataset_name)\n",
    "N,DIM = full_dataset.x.shape\n",
    "\n",
    "X,y = full_dataset.x, full_dataset.y\n",
    "\n",
    "if dataset_name==\"autos\":  \n",
    "    X = np.delete(X,[8],axis=1)\n",
    "\n",
    "if dataset_name == \"sml\":\n",
    "    X = np.delete(X,[2, 20, 21, 22],axis=1)\n",
    "\n",
    "\n",
    "X = X / np.std(X, axis=0)[None, :]\n",
    "y = y / np.std(y, axis=0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "y_train = y_train.squeeze()\n",
    "y_test = y_test.squeeze()\n",
    "\n",
    "# X_train = np.random.randn(1000, 5)\n",
    "# y_train = np.sin(X_train).sum(axis=1) + np.random.randn(1000) * 0.05\n",
    "# X_test = np.random.randn(500, 5)\n",
    "# y_test = np.sin(X_test).sum(axis=1) + np.random.randn(500) * 0.05\n",
    "# y_train = y_train.squeeze()\n",
    "# y_test = y_test.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_train.mean(0), X_test.mean(0))\n",
    "# print(X_train.std(0), X_test.std(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(y_train.mean(), y_train.std(),  y_test.mean(), y_test.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2308, 128), (257, 128))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True\n",
      "False False\n",
      "-0.49722314 -0.32346925\n",
      "0.13179375\n"
     ]
    }
   ],
   "source": [
    "likelihood = GaussianLikelihood()\n",
    "model = GPModel(to_torch(X_train), to_torch(y_train), likelihood, \n",
    "                # mean=ZeroMean(),\n",
    "                )\n",
    "\n",
    "print(model.training, likelihood.training)\n",
    "\n",
    "train_model(model, likelihood, to_torch(X_train), to_torch(y_train), training_iter=100, lr=0.1, seed=100)\n",
    "\n",
    "print(model.training,likelihood.training)\n",
    "\n",
    "\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "        preds = likelihood(model(to_torch(X_test)))\n",
    "\n",
    "print(negative_log_predictive_density(preds, to_torch(y_test)).numpy(), \n",
    "      mean_standardized_log_loss(preds,to_torch(y_test)).numpy(),\n",
    "      )\n",
    "print(np.sqrt(mean_squared_error(preds,to_torch(y_test)).numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = []\n",
    "for i in tqdm(range(5)):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42 + i)\n",
    "    y_train = y_train.squeeze()\n",
    "    y_test = y_test.squeeze()\n",
    "\n",
    "    likelihood = GaussianLikelihood()\n",
    "    model = GPModel(to_torch(X_train), to_torch(y_train), likelihood, \n",
    "                # mean=ZeroMean(),\n",
    "                )\n",
    "    train_model(model, likelihood, to_torch(X_train), to_torch(y_train), training_iter=100, lr=0.1, seed=100)\n",
    "    with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "        preds = likelihood(model(to_torch(X_test)))\n",
    "    rmse.append(np.sqrt(mean_squared_error(preds,to_torch(y_test)).numpy()))\n",
    "\n",
    "rmse = np.array(rmse)\n",
    "rmse.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse.mean(), rmse.std()/np.sqrt(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param_name, param in model.named_parameters():\n",
    "    print(f'Parameter name: {param_name:42} value = {param}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(1 + np.exp(-5.9791))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds.variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper,lower = preds.confidence_region()\n",
    "plt.plot(preds.mean.numpy())\n",
    "plt.fill_between(range(len(X_test)), upper,lower, alpha=0.3)\n",
    "plt.scatter(range(len(X_test)),y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additive kernel (GAM GP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAMGP(gpytorch.models.ExactGP):\n",
    "    def __init__(self, X_train, y_train, likelihood, d):\n",
    "        super().__init__(X_train, y_train, likelihood)\n",
    "\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(\n",
    "            gpytorch.kernels.RBFKernel(batch_shape=torch.Size([d]), ard_num_dims=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        mean = self.mean_module(X)\n",
    "        batched_dimensions_of_X = X.mT.unsqueeze(-1)  # Now a d x n x 1 tensor\n",
    "        covar = self.covar_module(batched_dimensions_of_X).sum(dim=-3)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean, covar)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpytorch.constraints\n",
    "\n",
    "\n",
    "likelihood = GaussianLikelihood(noise_constraint=gpytorch.constraints.GreaterThan(1e-3))\n",
    "model = GAMGP(to_torch(X_train),to_torch(y_train),likelihood, X_train.shape[1])\n",
    "\n",
    "print(model.training, likelihood.training)\n",
    "\n",
    "train_model(model, likelihood, to_torch(X_train), to_torch(y_train), training_iter=200, lr=0.1, seed=100)\n",
    "\n",
    "print(model.training,likelihood.training)\n",
    "\n",
    "\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "        preds = likelihood(model(to_torch(X_test)))\n",
    "\n",
    "print(\n",
    "      #   negative_log_predictive_density(preds, to_torch(y_test)).numpy(), \n",
    "      # mean_standardized_log_loss(preds,to_torch(y_test)).numpy(),\n",
    "      )\n",
    "print(np.sqrt(mean_squared_error(preds,to_torch(y_test)).numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script true\n",
    "for param_name, param in model.named_parameters():\n",
    "    print(f'Parameter name: {param_name:42} value = {param}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds.variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper,lower = preds.confidence_region()\n",
    "plt.plot(preds.mean.numpy())\n",
    "plt.fill_between(range(len(X_test)), upper,lower, alpha=0.3)\n",
    "plt.scatter(range(len(X_test)),y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additive GP with higher interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdditiveGP(gpytorch.models.ExactGP):\n",
    "    def __init__(self, X_train, y_train, likelihood, d, max_degree):\n",
    "        super().__init__(X_train, y_train, likelihood)\n",
    "\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.NewtonGirardAdditiveKernel(\n",
    "            RBFKernel(ard_num_dims=d), d, max_degree,\n",
    "        )\n",
    "            \n",
    "        # self.covar_module = gpytorch.kernels.ScaleKernel(\n",
    "        #     gpytorch.kernels.RBFKernel(batch_shape=torch.Size([d]), ard_num_dims=1)\n",
    "        # )\n",
    "\n",
    "        self.max_degree = max_degree\n",
    "\n",
    "    def forward(self, X):\n",
    "        mean = self.mean_module(X)\n",
    "        # batched_dimensions_of_X = X.mT.unsqueeze(-1)  # Now a d x n x 1 tensor\n",
    "        # univariate_rbf_covars = self.covar_module(batched_dimensions_of_X)\n",
    "        # covar = gpytorch.utils.sum_interaction_terms(\n",
    "        #     univariate_rbf_covars, max_degree=self.max_degree, dim=-3\n",
    "        # )\n",
    "        covar = self.covar_module(X)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean, covar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True\n",
      "False False\n",
      "\n",
      "0.08498737\n"
     ]
    }
   ],
   "source": [
    "# gpytorch.kernels.NewtonGirardAdditiveKernel will be substituted in the future with gpytorch.utils.sum_interaction_terms\n",
    "likelihood = GaussianLikelihood()\n",
    "max_degree =  1#X_train.shape[1] - 1  # if 1, then we are back to GAM GP\n",
    "model = AdditiveGP(to_torch(X_train),to_torch(y_train),likelihood, X_train.shape[1], max_degree)\n",
    "\n",
    "print(model.training, likelihood.training)\n",
    "train_model(model, likelihood, to_torch(X_train), to_torch(y_train), training_iter=100, lr=0.1, seed=100)\n",
    "print(model.training,likelihood.training)\n",
    "\n",
    "\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "        preds = likelihood(model(to_torch(X_test)))\n",
    "\n",
    "print(\n",
    "      #   negative_log_predictive_density(preds, to_torch(y_test)).numpy(), \n",
    "      # mean_standardized_log_loss(preds,to_torch(y_test)).numpy(),\n",
    "      )\n",
    "print(np.sqrt(mean_squared_error(preds,to_torch(y_test)).numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Product of kernels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 128, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 2308, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_projs = 20\n",
    "proj_dim = 1 #X_train.shape[1]//2\n",
    "np.random.seed(53)\n",
    "P_projs =  np.random.randn(num_projs,X_train.shape[1], proj_dim) / proj_dim\n",
    "print(P_projs.shape)\n",
    "\n",
    "torch.matmul(to_torch(X_train),to_torch(P_projs)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductKernelWithProjsGP(gpytorch.models.ExactGP):\n",
    "    def __init__(self, X_train, y_train,likelihood,P_projs):\n",
    "        num_projs, _,proj_dim = P_projs.shape\n",
    "        super().__init__(X_train, y_train, likelihood)\n",
    "\n",
    "        self.P_projs = P_projs\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(\n",
    "            gpytorch.kernels.RBFKernel(batch_shape=torch.Size([num_projs]), ard_num_dims=proj_dim),\n",
    "            batch_shape = torch.Size([]),   # this just matches the batch_shape of RBF but I only want 1 lengthscale...\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        mean = self.mean_module(X)\n",
    "        batched_X = torch.matmul(X,self.P_projs)\n",
    "        # covar = self.covar_module(batched_X).prod(dim=-3)# + self.covar_module(batched_X).sum(dim=-3) \n",
    "        covar = self.covar_module(batched_X).sum(dim=-3)   # This should be Delbridge's RP-GP-1 (without pre-projections)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean, covar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True\n",
      "False False\n",
      "0.09216766 0.7195612\n",
      "0.11932077\n"
     ]
    }
   ],
   "source": [
    "import gpytorch.constraints\n",
    "\n",
    "\n",
    "likelihood = GaussianLikelihood(\n",
    "      #   noise_constraint=gpytorch.constraints.Interval(1e-4,0.1),\n",
    "                                )\n",
    "\n",
    "model = ProductKernelWithProjsGP(to_torch(X_train),to_torch(y_train),likelihood, to_torch(P_projs))\n",
    "\n",
    "print(model.training, likelihood.training)\n",
    "train_model(model, likelihood, to_torch(X_train), to_torch(y_train), training_iter=100, lr=0.1, seed=100)\n",
    "print(model.training,likelihood.training)\n",
    "\n",
    "\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "        preds = likelihood(model(to_torch(X_test)))\n",
    "\n",
    "print(\n",
    "        negative_log_predictive_density(preds, to_torch(y_test)).numpy(), \n",
    "      mean_standardized_log_loss(preds,to_torch(y_test)).numpy(),\n",
    "      )\n",
    "print(np.sqrt(mean_squared_error(preds,to_torch(y_test)).numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script true\n",
    "for param_name, param in model.named_parameters():\n",
    "    print(f'Parameter name: {param_name:42} value = {param}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper,lower = preds.confidence_region()\n",
    "plt.plot(preds.mean.numpy())\n",
    "plt.fill_between(range(len(X_test)), upper,lower, alpha=0.3)\n",
    "plt.scatter(range(len(X_test)),y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Block Additive GPs with random projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in construction... this is BACK-UP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additive kernel and projection (joint learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dim = X_train.shape[1]\n",
    "\n",
    "class LargeFeatureExtractor(torch.nn.Sequential):           \n",
    "    def __init__(self, proj_dim):                                      \n",
    "        super(LargeFeatureExtractor, self).__init__()        \n",
    "        self.add_module('linear1', torch.nn.Linear(data_dim, 1000))\n",
    "        self.add_module('relu1', torch.nn.ReLU())                  \n",
    "        self.add_module('linear2', torch.nn.Linear(1000, 500))     \n",
    "        self.add_module('relu2', torch.nn.ReLU())                  \n",
    "        self.add_module('linear3', torch.nn.Linear(500, 50))       \n",
    "        self.add_module('relu3', torch.nn.ReLU())                  \n",
    "        self.add_module('linear4', torch.nn.Linear(50, proj_dim))    \n",
    "\n",
    "proj_dim = 5                                                           \n",
    "feature_extractor = LargeFeatureExtractor(proj_dim)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear1.weight :  Parameter containing:\n",
      "tensor([[ 0.0206, -0.0138,  0.0327,  ..., -0.0556, -0.0794, -0.0880],\n",
      "        [-0.0222,  0.0809,  0.0088,  ..., -0.0397, -0.0712, -0.0679],\n",
      "        [ 0.0059,  0.0103,  0.0486,  ..., -0.0500,  0.0136, -0.0846],\n",
      "        ...,\n",
      "        [-0.0802,  0.0723, -0.0592,  ..., -0.0402,  0.0039,  0.0550],\n",
      "        [-0.0350,  0.0206,  0.0100,  ...,  0.0115,  0.0053, -0.0091],\n",
      "        [ 0.0291,  0.0515,  0.0445,  ..., -0.0563,  0.0245,  0.0350]],\n",
      "       requires_grad=True)\n",
      "linear1.bias :  Parameter containing:\n",
      "tensor([ 0.0882,  0.0869,  0.0822, -0.0526, -0.0512, -0.0550,  0.0233, -0.0357,\n",
      "         0.0543, -0.0291,  0.0092,  0.0159, -0.0537, -0.0788,  0.0176, -0.0019,\n",
      "         0.0576,  0.0410, -0.0043,  0.0472, -0.0303,  0.0283, -0.0038, -0.0868,\n",
      "         0.0312, -0.0371, -0.0794, -0.0652, -0.0555, -0.0027,  0.0584, -0.0491,\n",
      "         0.0844,  0.0422, -0.0307,  0.0876,  0.0466, -0.0834, -0.0114,  0.0690,\n",
      "        -0.0342,  0.0167,  0.0496, -0.0088,  0.0318, -0.0451, -0.0529, -0.0165,\n",
      "         0.0360, -0.0365,  0.0085, -0.0277,  0.0351,  0.0138, -0.0086,  0.0147,\n",
      "         0.0800, -0.0701,  0.0080, -0.0211, -0.0664, -0.0853, -0.0486, -0.0646,\n",
      "         0.0283, -0.0843,  0.0071,  0.0101, -0.0068,  0.0434,  0.0167,  0.0269,\n",
      "         0.0651,  0.0771,  0.0393, -0.0873, -0.0729,  0.0884,  0.0311,  0.0216,\n",
      "        -0.0210,  0.0036, -0.0828, -0.0183, -0.0213,  0.0587,  0.0013, -0.0064,\n",
      "        -0.0008, -0.0505,  0.0094,  0.0612,  0.0880, -0.0504,  0.0358, -0.0834,\n",
      "         0.0465,  0.0023,  0.0432, -0.0854,  0.0105,  0.0483,  0.0033,  0.0868,\n",
      "         0.0091,  0.0108,  0.0314, -0.0218, -0.0166, -0.0694,  0.0772, -0.0708,\n",
      "         0.0559,  0.0731,  0.0189,  0.0701, -0.0061, -0.0724, -0.0880,  0.0554,\n",
      "         0.0237, -0.0536, -0.0762,  0.0586, -0.0315, -0.0114, -0.0376,  0.0728,\n",
      "         0.0095,  0.0283,  0.0368,  0.0305, -0.0354,  0.0859, -0.0326, -0.0608,\n",
      "         0.0772,  0.0022, -0.0173,  0.0023,  0.0550, -0.0061,  0.0219,  0.0513,\n",
      "         0.0165, -0.0343,  0.0276, -0.0184,  0.0554, -0.0876,  0.0830, -0.0880,\n",
      "        -0.0014, -0.0059,  0.0363, -0.0784,  0.0718, -0.0879, -0.0095,  0.0381,\n",
      "         0.0838,  0.0601,  0.0416,  0.0041,  0.0161, -0.0133,  0.0371,  0.0331,\n",
      "        -0.0119, -0.0443, -0.0465,  0.0439, -0.0525,  0.0534, -0.0732,  0.0651,\n",
      "        -0.0624, -0.0592, -0.0567, -0.0447, -0.0432, -0.0246,  0.0796, -0.0523,\n",
      "        -0.0643, -0.0660, -0.0435,  0.0215, -0.0584, -0.0786, -0.0502,  0.0707,\n",
      "        -0.0771,  0.0663,  0.0081, -0.0349, -0.0057,  0.0122, -0.0485,  0.0119,\n",
      "        -0.0136, -0.0184, -0.0232,  0.0332, -0.0583,  0.0631, -0.0451, -0.0113,\n",
      "        -0.0253, -0.0712,  0.0629, -0.0055,  0.0192, -0.0882, -0.0083,  0.0105,\n",
      "         0.0508,  0.0565,  0.0229, -0.0476,  0.0770, -0.0384,  0.0463, -0.0242,\n",
      "         0.0729,  0.0720, -0.0725, -0.0671,  0.0763, -0.0197,  0.0798,  0.0854,\n",
      "        -0.0595, -0.0349,  0.0065,  0.0600,  0.0230,  0.0350, -0.0155,  0.0517,\n",
      "        -0.0370,  0.0443,  0.0552,  0.0246,  0.0354, -0.0843, -0.0354,  0.0832,\n",
      "         0.0084,  0.0102, -0.0579,  0.0797,  0.0332,  0.0467, -0.0419, -0.0278,\n",
      "        -0.0418, -0.0116, -0.0304,  0.0158, -0.0517,  0.0366,  0.0169, -0.0521,\n",
      "        -0.0418, -0.0810, -0.0814,  0.0264, -0.0265, -0.0499, -0.0721,  0.0375,\n",
      "        -0.0704, -0.0408,  0.0777,  0.0738,  0.0488, -0.0099, -0.0181, -0.0500,\n",
      "         0.0293,  0.0503,  0.0123,  0.0428,  0.0677,  0.0480, -0.0605, -0.0640,\n",
      "         0.0018,  0.0094, -0.0297,  0.0173, -0.0464, -0.0246,  0.0409, -0.0821,\n",
      "        -0.0107,  0.0324, -0.0408, -0.0424,  0.0200, -0.0401, -0.0338, -0.0536,\n",
      "        -0.0732, -0.0766,  0.0428,  0.0335, -0.0503,  0.0173, -0.0448, -0.0002,\n",
      "         0.0774,  0.0629, -0.0140,  0.0345, -0.0442,  0.0605, -0.0319, -0.0302,\n",
      "         0.0737, -0.0858, -0.0207,  0.0600, -0.0621, -0.0158, -0.0487,  0.0374,\n",
      "        -0.0482, -0.0108,  0.0814,  0.0818,  0.0036,  0.0697,  0.0571,  0.0435,\n",
      "         0.0145,  0.0070,  0.0853, -0.0040, -0.0882, -0.0222,  0.0625, -0.0413,\n",
      "        -0.0655,  0.0696, -0.0393, -0.0609,  0.0006, -0.0597,  0.0224,  0.0545,\n",
      "         0.0462,  0.0848,  0.0057,  0.0627, -0.0209,  0.0161,  0.0597, -0.0101,\n",
      "         0.0068, -0.0884,  0.0368, -0.0184,  0.0145, -0.0455,  0.0718, -0.0163,\n",
      "         0.0194,  0.0314, -0.0306, -0.0272, -0.0675,  0.0087, -0.0554,  0.0569,\n",
      "        -0.0844,  0.0290, -0.0587,  0.0593, -0.0594, -0.0503,  0.0460,  0.0787,\n",
      "        -0.0809, -0.0553,  0.0083,  0.0810, -0.0752,  0.0198, -0.0505, -0.0709,\n",
      "         0.0802,  0.0634,  0.0417, -0.0362, -0.0441, -0.0297, -0.0678,  0.0404,\n",
      "         0.0037, -0.0117, -0.0728,  0.0231, -0.0708, -0.0037, -0.0090, -0.0277,\n",
      "         0.0101,  0.0061,  0.0852, -0.0677,  0.0672,  0.0682,  0.0443,  0.0537,\n",
      "         0.0851, -0.0261, -0.0797,  0.0216, -0.0733, -0.0025,  0.0222, -0.0770,\n",
      "        -0.0620, -0.0706, -0.0488,  0.0470, -0.0546, -0.0573,  0.0336,  0.0855,\n",
      "         0.0144,  0.0334,  0.0132, -0.0462, -0.0143, -0.0266, -0.0308, -0.0715,\n",
      "         0.0026,  0.0647, -0.0100,  0.0263, -0.0334, -0.0614,  0.0867, -0.0829,\n",
      "        -0.0618,  0.0865, -0.0618, -0.0098, -0.0783, -0.0709, -0.0240, -0.0175,\n",
      "        -0.0465,  0.0382,  0.0732,  0.0871,  0.0702, -0.0566,  0.0670, -0.0802,\n",
      "        -0.0736,  0.0779, -0.0718,  0.0661, -0.0450,  0.0143,  0.0670, -0.0157,\n",
      "        -0.0015, -0.0477, -0.0269,  0.0509,  0.0277,  0.0090, -0.0850,  0.0866,\n",
      "        -0.0810,  0.0321, -0.0200,  0.0367,  0.0558, -0.0290, -0.0241, -0.0453,\n",
      "        -0.0622, -0.0500, -0.0564,  0.0469, -0.0809, -0.0302, -0.0243,  0.0076,\n",
      "         0.0084,  0.0518, -0.0255, -0.0872,  0.0050, -0.0239,  0.0618,  0.0206,\n",
      "        -0.0483,  0.0356,  0.0659,  0.0728, -0.0234, -0.0208, -0.0498, -0.0457,\n",
      "        -0.0766,  0.0256, -0.0793,  0.0539, -0.0087, -0.0459,  0.0863, -0.0726,\n",
      "        -0.0572,  0.0545, -0.0377, -0.0575,  0.0859,  0.0576,  0.0732,  0.0268,\n",
      "        -0.0779,  0.0039, -0.0578,  0.0032,  0.0561, -0.0356,  0.0577,  0.0779,\n",
      "         0.0851,  0.0085,  0.0736, -0.0586,  0.0398, -0.0004, -0.0667, -0.0816,\n",
      "        -0.0492,  0.0091, -0.0778, -0.0542, -0.0397, -0.0091,  0.0855,  0.0662,\n",
      "        -0.0378, -0.0760, -0.0405,  0.0755, -0.0757, -0.0562,  0.0099, -0.0749,\n",
      "         0.0559,  0.0617, -0.0003,  0.0162, -0.0375, -0.0088, -0.0413, -0.0555,\n",
      "         0.0304, -0.0426, -0.0784,  0.0014,  0.0637,  0.0480,  0.0398, -0.0143,\n",
      "        -0.0419, -0.0463,  0.0794,  0.0821, -0.0156,  0.0248,  0.0444, -0.0363,\n",
      "        -0.0604,  0.0805, -0.0504, -0.0105,  0.0584, -0.0465, -0.0492, -0.0176,\n",
      "        -0.0243,  0.0123, -0.0363, -0.0135, -0.0197,  0.0304, -0.0745, -0.0145,\n",
      "        -0.0840, -0.0153, -0.0316, -0.0682,  0.0700, -0.0257, -0.0641, -0.0787,\n",
      "        -0.0253, -0.0123, -0.0101,  0.0051,  0.0810, -0.0630, -0.0246,  0.0801,\n",
      "        -0.0020, -0.0699,  0.0225,  0.0598, -0.0432,  0.0669,  0.0847,  0.0270,\n",
      "         0.0470,  0.0275, -0.0701,  0.0719, -0.0558,  0.0094, -0.0212,  0.0035,\n",
      "         0.0703,  0.0088, -0.0305, -0.0830, -0.0724, -0.0519, -0.0350,  0.0099,\n",
      "        -0.0772,  0.0186,  0.0363, -0.0730,  0.0025,  0.0556, -0.0468, -0.0851,\n",
      "         0.0168,  0.0841, -0.0870, -0.0848, -0.0835,  0.0570, -0.0456, -0.0775,\n",
      "        -0.0072,  0.0782, -0.0294, -0.0188,  0.0834,  0.0527,  0.0848,  0.0771,\n",
      "        -0.0263,  0.0601, -0.0576,  0.0772,  0.0093,  0.0358,  0.0848, -0.0106,\n",
      "         0.0388, -0.0776,  0.0418,  0.0742, -0.0542,  0.0577, -0.0852, -0.0770,\n",
      "        -0.0615,  0.0507,  0.0437,  0.0099,  0.0141,  0.0061, -0.0798, -0.0816,\n",
      "         0.0393,  0.0599, -0.0322, -0.0513,  0.0723,  0.0677,  0.0532, -0.0741,\n",
      "        -0.0768,  0.0291, -0.0028, -0.0782, -0.0455, -0.0857, -0.0327,  0.0078,\n",
      "         0.0572, -0.0153, -0.0758,  0.0609, -0.0235, -0.0338, -0.0404, -0.0581,\n",
      "        -0.0693,  0.0293,  0.0605, -0.0530, -0.0839, -0.0339,  0.0455, -0.0223,\n",
      "        -0.0008,  0.0354,  0.0297,  0.0595, -0.0841,  0.0877,  0.0781, -0.0081,\n",
      "        -0.0614,  0.0483, -0.0725, -0.0213, -0.0113, -0.0217, -0.0147, -0.0252,\n",
      "        -0.0842, -0.0257, -0.0801,  0.0482,  0.0274,  0.0748, -0.0476, -0.0846,\n",
      "         0.0232, -0.0365,  0.0246,  0.0558, -0.0731,  0.0807, -0.0344, -0.0863,\n",
      "         0.0103, -0.0089,  0.0692, -0.0115,  0.0193, -0.0173,  0.0529, -0.0059,\n",
      "        -0.0650, -0.0365, -0.0190,  0.0261, -0.0611, -0.0831, -0.0374,  0.0039,\n",
      "         0.0582, -0.0707,  0.0375,  0.0654, -0.0628,  0.0007,  0.0700,  0.0211,\n",
      "         0.0189, -0.0149, -0.0333,  0.0830, -0.0772, -0.0052,  0.0538, -0.0155,\n",
      "         0.0016, -0.0364, -0.0517,  0.0111,  0.0803,  0.0243,  0.0709, -0.0326,\n",
      "        -0.0033,  0.0267, -0.0872,  0.0444, -0.0338, -0.0494,  0.0288,  0.0505,\n",
      "         0.0674,  0.0189, -0.0357, -0.0476, -0.0564,  0.0146,  0.0873, -0.0146,\n",
      "         0.0093,  0.0812,  0.0112,  0.0623, -0.0241,  0.0744, -0.0163,  0.0098,\n",
      "        -0.0476,  0.0410,  0.0427, -0.0818, -0.0777, -0.0225,  0.0266,  0.0473,\n",
      "        -0.0149, -0.0292,  0.0557, -0.0718,  0.0478, -0.0472,  0.0168,  0.0228,\n",
      "        -0.0118, -0.0284, -0.0459, -0.0427,  0.0288,  0.0127,  0.0718,  0.0004,\n",
      "        -0.0547, -0.0533, -0.0629,  0.0127,  0.0663,  0.0865, -0.0157,  0.0243,\n",
      "         0.0294, -0.0563, -0.0180,  0.0289, -0.0427,  0.0241, -0.0312,  0.0418,\n",
      "        -0.0501,  0.0080, -0.0284, -0.0395, -0.0164,  0.0102,  0.0081,  0.0046,\n",
      "         0.0634, -0.0474,  0.0509, -0.0182, -0.0413, -0.0505, -0.0600, -0.0666,\n",
      "        -0.0880, -0.0639,  0.0578, -0.0731,  0.0240,  0.0030, -0.0351, -0.0394,\n",
      "        -0.0672, -0.0623,  0.0160,  0.0724, -0.0174,  0.0766,  0.0832,  0.0021,\n",
      "         0.0842,  0.0113,  0.0706, -0.0334,  0.0672, -0.0479, -0.0477,  0.0275,\n",
      "        -0.0158, -0.0093, -0.0640,  0.0043,  0.0415, -0.0689, -0.0694, -0.0021,\n",
      "         0.0245,  0.0457,  0.0296,  0.0755, -0.0586,  0.0543, -0.0625,  0.0146,\n",
      "         0.0759, -0.0143, -0.0739,  0.0206,  0.0684, -0.0578,  0.0413, -0.0804,\n",
      "        -0.0044, -0.0664, -0.0426, -0.0089,  0.0798, -0.0007,  0.0690,  0.0404,\n",
      "        -0.0595,  0.0345, -0.0711, -0.0087,  0.0258,  0.0332, -0.0517, -0.0341,\n",
      "         0.0049,  0.0418,  0.0729,  0.0325,  0.0623,  0.0312,  0.0068, -0.0315,\n",
      "        -0.0381,  0.0599, -0.0077,  0.0804, -0.0438,  0.0727,  0.0240, -0.0761,\n",
      "        -0.0304, -0.0762, -0.0158, -0.0779, -0.0064,  0.0550,  0.0129,  0.0276,\n",
      "         0.0192,  0.0235, -0.0289, -0.0732,  0.0253, -0.0879, -0.0130, -0.0767,\n",
      "         0.0629, -0.0517,  0.0346,  0.0402, -0.0137,  0.0710, -0.0473,  0.0390,\n",
      "        -0.0086, -0.0197, -0.0694, -0.0870,  0.0332, -0.0065, -0.0649,  0.0139,\n",
      "        -0.0667,  0.0712, -0.0665, -0.0880, -0.0267, -0.0531,  0.0816,  0.0731,\n",
      "         0.0136,  0.0774, -0.0670, -0.0760, -0.0839, -0.0562,  0.0687,  0.0852],\n",
      "       requires_grad=True)\n",
      "linear2.weight :  Parameter containing:\n",
      "tensor([[-0.0111,  0.0133,  0.0148,  ...,  0.0205,  0.0088,  0.0207],\n",
      "        [ 0.0242,  0.0295,  0.0039,  ..., -0.0264,  0.0073, -0.0292],\n",
      "        [-0.0119, -0.0033,  0.0183,  ...,  0.0077,  0.0291, -0.0297],\n",
      "        ...,\n",
      "        [-0.0253,  0.0100,  0.0159,  ...,  0.0206,  0.0024, -0.0233],\n",
      "        [ 0.0277, -0.0120,  0.0145,  ..., -0.0247,  0.0181, -0.0053],\n",
      "        [ 0.0006, -0.0073,  0.0048,  ...,  0.0004, -0.0115, -0.0056]],\n",
      "       requires_grad=True)\n",
      "linear2.bias :  Parameter containing:\n",
      "tensor([ 2.4993e-03, -7.5338e-03,  2.3644e-02,  2.9739e-02, -1.6828e-02,\n",
      "         8.8279e-03, -6.2215e-03, -1.6906e-03,  2.3779e-02,  1.1696e-02,\n",
      "        -6.8384e-03, -8.2078e-03, -2.0256e-02, -1.8032e-02,  2.4999e-02,\n",
      "        -1.1460e-02,  1.4445e-02,  1.1739e-02, -1.7090e-02,  2.2213e-02,\n",
      "         2.6958e-02, -1.1119e-02, -2.2434e-02,  2.4431e-02, -3.1194e-02,\n",
      "        -2.1908e-02, -9.1633e-03, -2.4090e-02, -5.9501e-03, -1.1983e-02,\n",
      "         1.3370e-02, -5.4729e-03,  1.4488e-02,  1.2675e-02, -9.4715e-03,\n",
      "         2.8894e-02,  2.1853e-02, -2.6208e-02, -6.6371e-04,  1.9175e-02,\n",
      "        -6.8410e-03, -2.9305e-02,  1.3665e-02, -8.1281e-03, -5.6672e-03,\n",
      "         4.1639e-03,  2.9126e-02, -1.0743e-02, -1.0969e-02, -1.0934e-02,\n",
      "         1.1799e-02,  1.9460e-02,  2.9395e-02,  1.6348e-02,  2.3979e-02,\n",
      "         9.7904e-03, -2.9274e-02,  1.5610e-02,  4.1944e-03,  2.3385e-02,\n",
      "         3.0063e-02,  2.8695e-02, -6.3332e-03,  2.5144e-02, -1.9239e-02,\n",
      "         3.0578e-02,  2.3363e-02,  1.6049e-02, -2.2832e-02,  2.1480e-02,\n",
      "        -7.2168e-03,  5.0788e-03,  3.1065e-02,  2.8886e-02,  1.9559e-02,\n",
      "         7.1817e-03,  1.1697e-02, -2.8960e-02, -2.8695e-02, -2.9727e-02,\n",
      "        -7.5520e-03, -2.4006e-02,  2.7683e-02, -2.0408e-02,  1.7007e-02,\n",
      "        -3.1366e-02,  1.1803e-02,  3.1004e-02,  1.4025e-02, -9.1499e-03,\n",
      "         6.1259e-03,  9.6582e-03,  2.1803e-02, -2.7726e-02, -2.2051e-02,\n",
      "        -2.4239e-02,  1.5280e-02, -1.5920e-02,  2.4320e-02, -3.1398e-02,\n",
      "         2.7444e-02, -2.3070e-02, -8.4711e-03,  1.4133e-02,  2.3046e-02,\n",
      "         1.7635e-02,  2.0147e-02, -2.8726e-02,  3.0564e-02, -8.6071e-03,\n",
      "         1.7941e-02,  6.4063e-03, -3.3327e-03,  3.0087e-02, -1.4780e-02,\n",
      "        -1.2725e-02,  2.7161e-02, -2.3290e-02, -2.2450e-02,  1.6899e-02,\n",
      "        -1.2224e-02, -1.0074e-02, -1.6223e-02,  2.3143e-02,  2.6522e-02,\n",
      "         1.3759e-02, -2.0848e-02,  9.0096e-03, -3.0390e-02,  1.1854e-03,\n",
      "         1.1394e-02, -1.8277e-02, -1.0498e-02,  2.1764e-02, -2.2479e-03,\n",
      "        -1.0322e-02, -1.9475e-02,  1.2919e-02,  1.1945e-02, -3.0589e-02,\n",
      "         9.8479e-03,  9.1597e-03,  2.5238e-02,  4.4928e-03, -1.8888e-02,\n",
      "        -1.5900e-02, -8.9205e-04,  1.0470e-02, -5.5386e-03, -2.8953e-02,\n",
      "         2.7702e-02,  1.2555e-02,  2.1595e-03,  2.4300e-02,  2.7706e-02,\n",
      "        -4.1795e-03,  2.7810e-02,  3.4689e-03, -4.5190e-03, -1.4105e-02,\n",
      "        -6.8525e-03, -2.7683e-02, -9.5225e-03,  3.1261e-02,  3.0026e-02,\n",
      "        -1.2144e-02,  2.6463e-02, -1.6364e-02, -1.7794e-02, -1.5385e-02,\n",
      "         1.3999e-02, -1.4327e-02, -1.9696e-02, -3.0992e-02,  2.7707e-03,\n",
      "        -1.9395e-02,  2.9168e-02, -2.2262e-02, -7.7242e-03, -2.5708e-02,\n",
      "        -1.3410e-04,  2.9033e-02,  1.8208e-03,  1.9810e-02, -9.5565e-05,\n",
      "        -1.1400e-02, -1.8449e-02, -1.3225e-02,  1.6141e-02, -2.5754e-02,\n",
      "        -8.2928e-03,  1.9710e-02,  2.3049e-02,  5.3265e-03,  2.2538e-02,\n",
      "         1.7730e-03,  2.9440e-02, -7.5048e-03, -1.2644e-02,  2.3661e-02,\n",
      "         4.6681e-03,  3.0676e-02,  2.5667e-02, -1.9112e-02, -2.8147e-02,\n",
      "         2.7398e-02, -2.6698e-02, -1.0924e-02, -5.7735e-03, -1.7498e-04,\n",
      "        -2.3108e-02, -1.6695e-02,  3.1610e-02,  3.1470e-02,  2.7018e-02,\n",
      "        -6.5095e-03,  1.5656e-02, -2.7231e-02,  1.0753e-02,  2.8458e-02,\n",
      "        -2.7282e-02,  1.4448e-02,  1.1884e-02,  2.9066e-02,  3.1193e-02,\n",
      "         1.5289e-02,  9.6590e-03, -5.3187e-03, -2.2794e-03, -1.5317e-02,\n",
      "        -2.0495e-02, -8.6150e-03, -7.4027e-03,  7.2791e-03,  1.4971e-02,\n",
      "         2.4970e-04, -2.5673e-02,  2.9282e-02,  2.4073e-02, -2.9071e-02,\n",
      "         2.7460e-02,  8.9969e-03,  1.6811e-02, -8.1091e-04, -1.9371e-02,\n",
      "         2.2878e-02,  2.0001e-02, -2.7157e-02, -1.5634e-02,  2.7002e-02,\n",
      "        -8.7105e-03, -2.0366e-02, -1.1952e-02,  2.2889e-02,  9.1303e-03,\n",
      "        -8.7616e-03, -6.2027e-03, -3.9471e-03,  1.1063e-02,  6.6629e-04,\n",
      "        -1.3158e-02, -1.5715e-02, -1.4693e-02, -3.9702e-03,  2.7514e-02,\n",
      "         5.3562e-03,  1.6207e-02,  2.8447e-02, -3.0031e-02,  1.2696e-02,\n",
      "         1.5352e-02, -1.7106e-02,  1.4313e-02,  7.5294e-03, -1.8137e-02,\n",
      "        -3.8670e-03,  2.6223e-02,  3.1498e-02,  9.0366e-03,  3.4944e-03,\n",
      "        -1.9548e-02, -1.9867e-02, -2.6098e-02,  2.2637e-02,  2.5252e-02,\n",
      "         2.3477e-02, -1.7596e-02, -1.4499e-02,  2.0940e-02, -1.8192e-03,\n",
      "         2.2195e-02,  3.0585e-02, -8.9819e-03,  1.3160e-02,  1.4646e-02,\n",
      "         1.8317e-02, -2.2319e-02,  5.9664e-03,  1.7492e-02, -2.1660e-02,\n",
      "        -9.4234e-03, -3.0175e-02,  2.7413e-02,  1.2611e-02, -3.1466e-02,\n",
      "         2.1409e-02,  2.3826e-02, -2.0824e-02,  9.1037e-03, -2.9330e-03,\n",
      "         1.5570e-02,  3.1583e-02, -2.0184e-02, -1.4506e-02,  2.7233e-03,\n",
      "        -1.6470e-03, -3.0019e-02,  1.9274e-02, -3.0118e-02, -1.5652e-02,\n",
      "         1.6171e-03,  2.2733e-02, -2.0418e-02, -1.2102e-02,  1.8365e-02,\n",
      "         2.4332e-02, -6.5380e-03,  4.9929e-04,  1.0119e-02, -1.9562e-02,\n",
      "         1.6861e-02,  3.3330e-03,  2.9925e-02, -6.1513e-03,  1.8022e-02,\n",
      "        -2.1575e-02, -3.1392e-02,  4.8092e-03, -1.8814e-02,  2.4882e-02,\n",
      "        -3.2357e-03, -1.8670e-02,  2.8215e-02,  1.9914e-02, -1.8389e-02,\n",
      "        -2.0780e-02,  2.0305e-02, -2.4555e-02,  1.2001e-02,  1.1666e-02,\n",
      "         2.1310e-02, -1.6115e-02,  2.4779e-02,  2.0846e-02, -4.9366e-03,\n",
      "        -1.5593e-02,  2.2165e-06,  3.0077e-02,  1.8266e-02,  1.0789e-02,\n",
      "        -1.1020e-02, -2.9320e-02, -2.9515e-02, -1.8828e-02, -3.1091e-05,\n",
      "         2.8337e-02,  1.4693e-02,  2.6764e-02,  2.3618e-02,  1.8742e-02,\n",
      "         3.0108e-03,  2.1261e-02,  2.6708e-02,  1.5598e-03, -1.5563e-02,\n",
      "        -1.2386e-02, -2.9433e-02,  6.0256e-03,  1.9588e-02, -2.1101e-02,\n",
      "        -1.4077e-02, -1.0006e-02, -1.0035e-04,  7.9687e-03,  2.4230e-02,\n",
      "         1.5985e-02,  2.2193e-02,  4.4592e-03,  1.5106e-02, -6.3088e-03,\n",
      "         1.5709e-02, -3.1333e-02, -1.7760e-02, -2.5074e-02,  5.4137e-03,\n",
      "         1.5490e-03, -2.8982e-02,  3.1353e-02, -1.3066e-02,  1.1517e-02,\n",
      "        -6.3098e-03,  9.2006e-03, -2.7721e-04, -2.3062e-02, -7.3613e-03,\n",
      "         1.6155e-02, -4.1554e-03, -1.0828e-02,  2.9244e-02,  1.0522e-02,\n",
      "        -2.7301e-03, -3.1591e-02, -2.1015e-02, -2.4293e-02,  2.7519e-02,\n",
      "         1.4420e-02,  1.1828e-02,  4.5219e-03, -1.5604e-02, -2.7187e-02,\n",
      "         1.8447e-02, -1.0769e-03,  2.9783e-02,  1.9385e-02,  7.8215e-03,\n",
      "         1.2271e-02,  2.1898e-02, -2.8963e-02,  2.9639e-02, -5.6972e-03,\n",
      "         2.3400e-02,  1.9595e-02,  2.0394e-02, -5.8748e-03, -5.4039e-03,\n",
      "         1.2036e-02,  2.6164e-02, -1.3287e-02,  3.1438e-02, -5.0225e-03,\n",
      "         3.7124e-03,  8.6365e-03,  6.1456e-03, -9.1262e-03,  1.8736e-02,\n",
      "        -2.2980e-02,  1.0434e-02,  2.4372e-03, -9.0022e-03, -2.7357e-02,\n",
      "         1.0924e-03,  3.1255e-02, -2.8356e-02,  4.1115e-03, -1.3134e-02,\n",
      "        -8.1887e-04,  5.2731e-03,  1.0114e-02,  3.6807e-03,  6.1974e-03,\n",
      "        -1.0646e-02, -1.2206e-02,  2.4991e-02, -2.1669e-03,  1.4263e-02,\n",
      "         4.0567e-03, -2.7938e-02,  1.5637e-02,  7.9748e-03,  8.1489e-03,\n",
      "         1.5876e-02, -2.5854e-02, -2.9038e-02, -9.5186e-03, -2.2197e-02,\n",
      "        -2.9865e-02, -3.7188e-03,  2.1452e-02,  1.3652e-02, -1.1841e-02,\n",
      "         3.3430e-03,  2.6538e-02, -3.0047e-03,  1.7829e-02, -3.1002e-02,\n",
      "         1.8001e-02, -1.7253e-02, -6.5179e-03,  2.3984e-02, -3.1548e-02,\n",
      "         1.5334e-02,  9.1636e-03,  1.6415e-02, -2.1509e-02,  6.7743e-03,\n",
      "        -3.0629e-02,  2.9643e-02,  2.8191e-02, -1.9430e-02,  2.3910e-02],\n",
      "       requires_grad=True)\n",
      "linear3.weight :  Parameter containing:\n",
      "tensor([[-4.0875e-02,  3.9038e-02,  4.1628e-02,  ...,  4.6891e-03,\n",
      "          3.4626e-02,  4.2240e-02],\n",
      "        [-2.3122e-02, -3.3507e-02,  3.8278e-02,  ..., -1.3810e-02,\n",
      "         -4.1869e-03,  1.8584e-02],\n",
      "        [ 3.0487e-02, -3.7346e-02, -2.0378e-02,  ...,  2.7349e-03,\n",
      "         -3.9445e-02, -5.4955e-03],\n",
      "        ...,\n",
      "        [-4.0261e-02, -2.9404e-02, -1.5107e-02,  ..., -2.6199e-02,\n",
      "          3.2945e-02, -3.9861e-02],\n",
      "        [ 1.4708e-02, -2.6838e-02,  2.8041e-02,  ..., -1.3353e-02,\n",
      "         -3.9556e-02,  8.2016e-03],\n",
      "        [-1.7802e-02,  2.3810e-02, -3.8385e-05,  ...,  2.5352e-02,\n",
      "         -1.7078e-02, -3.8639e-02]], requires_grad=True)\n",
      "linear3.bias :  Parameter containing:\n",
      "tensor([ 0.0349, -0.0164,  0.0438,  0.0267,  0.0004, -0.0088, -0.0416,  0.0090,\n",
      "         0.0100, -0.0369,  0.0032, -0.0272, -0.0231,  0.0051, -0.0215, -0.0017,\n",
      "         0.0366,  0.0130, -0.0214, -0.0330, -0.0248,  0.0356,  0.0357, -0.0109,\n",
      "        -0.0052,  0.0374,  0.0329,  0.0247,  0.0103, -0.0153,  0.0329, -0.0210,\n",
      "        -0.0226, -0.0267, -0.0273,  0.0384,  0.0112, -0.0386, -0.0309, -0.0202,\n",
      "        -0.0237, -0.0236,  0.0247, -0.0140,  0.0071,  0.0383,  0.0318, -0.0200,\n",
      "         0.0099, -0.0297], requires_grad=True)\n",
      "linear4.weight :  Parameter containing:\n",
      "tensor([[ 0.0421,  0.0383,  0.1009,  0.1245,  0.1020, -0.0126,  0.0514, -0.1039,\n",
      "         -0.0553,  0.1393,  0.1314,  0.0523,  0.0701,  0.1313,  0.1241, -0.1020,\n",
      "          0.1366, -0.0506, -0.0210,  0.0098,  0.1212,  0.1225, -0.1216,  0.0232,\n",
      "         -0.0002,  0.0736,  0.0112, -0.0630, -0.0789,  0.1364,  0.1224,  0.0525,\n",
      "         -0.1397,  0.0526,  0.0149,  0.0466,  0.0377,  0.0315,  0.0161,  0.1262,\n",
      "         -0.0690, -0.1291, -0.1217, -0.0868, -0.0493,  0.1165, -0.0111,  0.0764,\n",
      "         -0.0030, -0.1384],\n",
      "        [-0.1261, -0.0540, -0.0285,  0.0176, -0.1167, -0.0548,  0.1334,  0.0256,\n",
      "         -0.0352, -0.1071,  0.1120, -0.0781,  0.0099, -0.1126, -0.0703,  0.0285,\n",
      "         -0.0664,  0.1108, -0.0766,  0.0066, -0.1334, -0.1234, -0.1398,  0.0497,\n",
      "          0.0124, -0.1090,  0.0945,  0.1110, -0.0951,  0.0755,  0.0271, -0.0979,\n",
      "         -0.1311, -0.1206,  0.1382, -0.0135,  0.1380,  0.0259, -0.0939, -0.0785,\n",
      "         -0.0295,  0.0077,  0.0350, -0.0856, -0.0889,  0.0934, -0.0067, -0.1372,\n",
      "          0.0800,  0.0882],\n",
      "        [-0.0338, -0.1277,  0.0072,  0.0686, -0.1218, -0.0191, -0.0867, -0.0419,\n",
      "          0.0925, -0.1405,  0.0761,  0.1121, -0.1330, -0.0017,  0.0621,  0.1161,\n",
      "         -0.0580, -0.0527,  0.0295,  0.0838,  0.1361, -0.0596,  0.0613,  0.1315,\n",
      "          0.1044,  0.1076, -0.1265,  0.0765, -0.0365, -0.1160,  0.1095,  0.0380,\n",
      "         -0.1254, -0.1164,  0.1393,  0.0281,  0.0589, -0.0353, -0.1184, -0.1359,\n",
      "          0.1219,  0.0590,  0.1163, -0.0060,  0.0241, -0.0115, -0.1031, -0.0472,\n",
      "          0.0953, -0.0967],\n",
      "        [-0.0269, -0.0980,  0.0499, -0.1377,  0.0022,  0.0396, -0.0710, -0.1038,\n",
      "         -0.1236, -0.0894,  0.1264,  0.0920,  0.0127, -0.0548, -0.0687,  0.1110,\n",
      "         -0.0022,  0.0069,  0.0376, -0.1011,  0.0418,  0.1311,  0.1188, -0.0617,\n",
      "         -0.0874,  0.0760,  0.0640, -0.1170, -0.1220,  0.0563, -0.0810,  0.0339,\n",
      "         -0.0228, -0.1356,  0.1367, -0.1083,  0.0491, -0.1376, -0.0348,  0.0909,\n",
      "         -0.0793, -0.0034,  0.0330,  0.0942,  0.0293, -0.0748,  0.1085, -0.0148,\n",
      "         -0.0804, -0.0007],\n",
      "        [ 0.0790,  0.0394, -0.1276,  0.0077,  0.0337,  0.0958,  0.0202, -0.0343,\n",
      "          0.0726,  0.0836, -0.0170,  0.0148, -0.1321,  0.0811, -0.0745, -0.0332,\n",
      "          0.0626,  0.1327, -0.0742,  0.0437, -0.0731, -0.0210, -0.0625,  0.0093,\n",
      "         -0.1194, -0.1354,  0.0692,  0.0037, -0.0633, -0.0993, -0.1037,  0.0973,\n",
      "          0.1142,  0.0110,  0.0031, -0.1260, -0.0338,  0.1134,  0.1322, -0.0779,\n",
      "          0.0227,  0.1053,  0.0427, -0.0343,  0.0546,  0.0823,  0.0669,  0.1356,\n",
      "         -0.0720, -0.1295]], requires_grad=True)\n",
      "linear4.bias :  Parameter containing:\n",
      "tensor([-0.0909,  0.0509, -0.0950, -0.1291, -0.0220], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for name,values in feature_extractor.named_parameters():\n",
    "    print(name,\": \", values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): LargeFeatureExtractor(\n",
       "    (linear1): Linear(in_features=128, out_features=1000, bias=True)\n",
       "    (relu1): ReLU()\n",
       "    (linear2): Linear(in_features=1000, out_features=500, bias=True)\n",
       "    (relu2): ReLU()\n",
       "    (linear3): Linear(in_features=500, out_features=50, bias=True)\n",
       "    (relu3): ReLU()\n",
       "    (linear4): Linear(in_features=50, out_features=5, bias=True)\n",
       "  )\n",
       "  (1): Tanh()\n",
       "  (2): Linear(in_features=5, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_model = torch.nn.Sequential(feature_extractor,\n",
    "                                  torch.nn.Tanh(),\n",
    "                                  torch.nn.Linear(proj_dim,1),\n",
    "\n",
    ")\n",
    "dummy_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:09<00:00,  8.01it/s]\n"
     ]
    }
   ],
   "source": [
    "# Pre-train the DNN as in Wilson et al. (2015) paper\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "dummy_model.train()\n",
    "\n",
    "# Create DataLoader for mini-batch training\n",
    "batch_size = 50\n",
    "train_dataset = TensorDataset(to_torch(X_train), to_torch(y_train).squeeze(-1))\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# loss function and optimizer\n",
    "loss_fn = torch.nn.MSELoss()  # mean square error\n",
    "optimizer = torch.optim.Adam(dummy_model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 80\n",
    "loss_vals = []\n",
    "for i in tqdm(range(num_epochs)):\n",
    "    for X_batch, y_batch in train_loader:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = dummy_model(X_batch)\n",
    "        loss = loss_fn(y_pred.squeeze(),y_batch.squeeze())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_vals.append(loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x33f44a440>]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12440015619311655"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_model.eval()\n",
    "y_pred = dummy_model(to_torch(X_test))\n",
    "mse = loss_fn(y_pred.squeeze(), to_torch(y_test))\n",
    "mse = float(mse)\n",
    "np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear1.weight :  Parameter containing:\n",
      "tensor([[ 0.0685, -0.0170,  0.0585,  ..., -0.0565, -0.0836, -0.0886],\n",
      "        [ 0.0016,  0.0734,  0.0040,  ..., -0.0638, -0.0833, -0.0535],\n",
      "        [-0.0092, -0.0118,  0.0553,  ..., -0.0525,  0.0073, -0.0771],\n",
      "        ...,\n",
      "        [-0.0652,  0.0625, -0.0466,  ..., -0.0431,  0.0044,  0.0681],\n",
      "        [-0.0189, -0.0004,  0.0270,  ..., -0.0118, -0.0050,  0.0177],\n",
      "        [ 0.0315,  0.0816,  0.0678,  ..., -0.0636,  0.0167,  0.0346]],\n",
      "       requires_grad=True)\n",
      "linear1.bias :  Parameter containing:\n",
      "tensor([ 1.3079e-01,  1.3545e-01, -9.1551e-03, -1.1516e-01, -5.9742e-02,\n",
      "        -1.4904e-01,  6.4093e-02,  4.8827e-02,  1.2895e-01, -1.6786e-02,\n",
      "        -6.1949e-02,  5.5359e-02, -1.3411e-01, -1.3914e-01, -1.3959e-02,\n",
      "         4.1725e-02, -5.7183e-02,  1.2599e-01, -9.0791e-02, -2.2027e-02,\n",
      "        -6.8517e-02, -2.5689e-02, -8.4163e-02, -2.5399e-01, -3.6460e-02,\n",
      "        -1.2530e-01, -1.7321e-01, -9.3334e-02, -2.2373e-01,  3.5139e-02,\n",
      "         1.7181e-01,  5.0393e-02,  1.5612e-01, -1.7498e-02, -7.7283e-03,\n",
      "         1.5666e-02,  9.3159e-02, -2.5926e-01, -6.8132e-02,  1.0842e-01,\n",
      "         2.0327e-02,  1.3278e-01,  1.4675e-01, -1.2796e-02, -4.7072e-03,\n",
      "        -1.8249e-01, -1.2226e-01,  1.0022e-03,  6.1821e-02, -1.3798e-01,\n",
      "         7.3125e-02,  4.0479e-03,  8.3286e-02, -5.2180e-02, -7.0943e-02,\n",
      "        -3.6097e-02, -2.9138e-02, -5.3209e-02,  1.1457e-01, -1.6468e-01,\n",
      "        -9.4796e-02, -1.4764e-01, -1.2598e-01, -1.9864e-01, -3.4344e-02,\n",
      "        -1.0269e-04,  5.5675e-02, -5.8379e-02, -5.3563e-02,  1.0892e-01,\n",
      "        -2.7912e-03, -1.0999e-02, -1.1858e-02,  2.8239e-02,  9.3456e-02,\n",
      "        -2.2343e-01, -1.3984e-01,  7.3171e-03,  1.1249e-01,  1.1803e-01,\n",
      "        -9.2453e-02, -1.4673e-01, -1.4650e-01, -8.2851e-02, -2.5130e-02,\n",
      "         9.1631e-02, -2.8543e-03,  2.4051e-02,  6.5417e-02, -7.0637e-02,\n",
      "        -1.0151e-01,  3.7457e-02,  1.0381e-01, -6.9738e-02,  1.4809e-01,\n",
      "        -2.8197e-02,  2.9264e-02, -6.7788e-02,  1.1060e-02, -1.6651e-01,\n",
      "        -4.4198e-02, -7.1815e-02, -6.8319e-02,  1.3783e-01,  7.6547e-02,\n",
      "        -1.5691e-01, -4.5598e-02, -1.5421e-01, -1.6513e-02, -4.1030e-02,\n",
      "         1.0582e-02, -1.4963e-01,  1.0133e-01,  9.2343e-02,  6.2468e-02,\n",
      "         9.1508e-02, -1.6855e-02, -5.2716e-02, -1.2980e-01,  5.1677e-02,\n",
      "         1.5373e-02, -4.5071e-02, -2.2982e-01, -9.3899e-02, -1.4311e-02,\n",
      "        -1.4563e-01, -7.2461e-03,  1.0759e-01, -6.6107e-02, -1.0366e-01,\n",
      "        -5.3787e-03, -2.3350e-02,  5.8928e-02,  3.8533e-02,  6.8455e-02,\n",
      "        -1.5186e-01,  2.6359e-02,  6.3889e-03, -1.5788e-01, -1.0173e-02,\n",
      "         9.2834e-02, -5.8533e-02,  7.9902e-02,  1.2693e-01, -4.4427e-02,\n",
      "        -1.9157e-01,  8.6941e-02, -4.6272e-02,  3.8622e-02, -2.8356e-01,\n",
      "         1.8497e-01, -9.1555e-02, -4.2152e-02, -1.0710e-02,  7.5369e-02,\n",
      "        -2.5989e-01,  1.1768e-01, -2.5414e-01, -9.2734e-02,  3.5288e-02,\n",
      "         1.2959e-01, -7.1780e-02, -1.2310e-02, -4.5981e-02,  6.5070e-02,\n",
      "         2.0180e-02, -6.4824e-03, -1.1931e-01, -6.6983e-02, -1.0597e-01,\n",
      "        -2.0772e-01,  8.1549e-02, -1.9225e-01,  2.6641e-02, -1.2213e-01,\n",
      "         7.2041e-02, -6.3407e-02, -8.8662e-02, -1.1718e-01, -1.3900e-01,\n",
      "        -1.4421e-01, -5.8533e-02,  1.1756e-01, -1.6461e-02, -1.3140e-01,\n",
      "        -1.2202e-01, -1.9378e-01,  5.3443e-02, -1.4226e-01, -2.0470e-01,\n",
      "        -2.7252e-02,  6.1077e-03, -2.5360e-02,  8.6333e-03,  9.3075e-02,\n",
      "        -1.1463e-01,  8.6786e-02,  9.1850e-02, -2.5988e-01,  1.9317e-02,\n",
      "         2.4421e-03, -1.3154e-02, -1.1973e-01, -1.2247e-02, -1.2009e-01,\n",
      "         8.9521e-02, -1.4404e-01,  2.7379e-02, -1.8427e-01, -2.6318e-01,\n",
      "         7.4911e-02, -4.5419e-02,  5.7643e-02, -2.6735e-01, -3.6692e-02,\n",
      "        -3.2444e-02, -9.6617e-02,  2.1041e-01,  2.9669e-02, -1.3051e-01,\n",
      "         1.5954e-01, -8.1569e-03,  1.3357e-01, -1.0600e-01, -1.6081e-02,\n",
      "         1.5144e-01, -1.5343e-01, -1.5387e-01,  1.3807e-01,  5.2169e-02,\n",
      "         1.1949e-02,  1.4320e-01, -1.2965e-01, -3.8235e-02, -3.7777e-02,\n",
      "         1.6607e-01, -7.3130e-02, -8.0099e-02, -5.4754e-02,  5.2770e-02,\n",
      "        -9.5169e-02,  5.7819e-02,  3.0739e-02,  3.7864e-02, -6.8205e-02,\n",
      "        -9.3702e-02, -1.5869e-01,  2.2341e-01,  1.7601e-01, -2.4345e-02,\n",
      "        -2.6915e-01,  2.5635e-01,  3.5137e-02,  2.1762e-03, -1.0699e-01,\n",
      "        -6.5911e-02, -8.4261e-02, -8.1685e-02,  2.7305e-02,  8.3438e-02,\n",
      "        -8.0299e-02,  4.1345e-02, -4.1889e-02, -1.8631e-01,  2.8399e-03,\n",
      "        -1.0984e-01, -1.3486e-02, -6.2216e-02, -1.7827e-01, -3.8408e-02,\n",
      "        -1.9116e-01,  1.2887e-03, -5.6968e-02, -1.8195e-01,  5.5331e-02,\n",
      "         2.9434e-02, -2.1889e-02,  5.2643e-02, -6.0205e-02, -1.4825e-01,\n",
      "        -7.4922e-02,  8.8740e-02,  7.7386e-02,  1.5246e-01,  5.0692e-02,\n",
      "         1.0975e-01, -1.6271e-01, -1.5794e-01, -2.0998e-02,  8.5371e-02,\n",
      "        -1.3647e-01, -3.5585e-02,  4.2397e-02, -1.0946e-01,  5.2713e-02,\n",
      "        -1.4972e-01, -3.5079e-02,  1.1173e-01, -1.2033e-01, -1.9133e-01,\n",
      "         7.8296e-02, -9.8666e-02, -1.0280e-01,  9.7056e-03, -1.1686e-01,\n",
      "        -4.8779e-02,  1.9725e-01, -1.0948e-01, -4.2125e-02, -7.4554e-02,\n",
      "        -7.9933e-02, -1.2300e-01,  1.3967e-01,  1.3662e-01,  5.4117e-02,\n",
      "        -6.4076e-02, -9.1527e-02, -8.0117e-02,  1.2008e-02,  2.9103e-02,\n",
      "         7.3993e-02, -1.3347e-01,  2.4460e-02, -4.7841e-02, -1.5948e-01,\n",
      "        -8.2963e-02,  1.4276e-01,  9.6894e-02, -6.7325e-02,  3.5087e-02,\n",
      "         1.1764e-01, -3.8991e-03,  5.3326e-02,  1.5462e-01,  1.2210e-01,\n",
      "         9.6865e-02, -9.0818e-02, -4.3089e-02,  1.4587e-01,  4.0387e-02,\n",
      "        -1.1938e-01,  5.1984e-02,  1.2058e-01, -8.4441e-02, -8.6036e-02,\n",
      "         1.6500e-02, -3.1819e-02, -6.1859e-02, -5.9175e-02, -3.4118e-03,\n",
      "         9.2147e-02, -1.4994e-02,  1.3564e-01,  1.6621e-01,  6.3027e-02,\n",
      "        -6.3882e-02, -8.9273e-02, -2.1294e-02, -4.6013e-02, -3.9566e-02,\n",
      "         8.0968e-02, -2.2061e-01,  1.0852e-01, -2.9573e-03,  4.0201e-03,\n",
      "        -1.9673e-01,  6.7316e-02,  1.5787e-02, -4.6005e-02,  5.0423e-02,\n",
      "        -1.4508e-01, -1.5126e-01, -2.2660e-01,  1.6023e-04, -1.8420e-02,\n",
      "         2.6701e-02, -7.3759e-02, -2.3650e-02, -1.3909e-01, -3.3944e-02,\n",
      "        -1.2053e-01, -2.1399e-01,  4.8213e-02,  1.4218e-01, -1.6501e-01,\n",
      "        -1.0713e-01, -6.7350e-03,  1.5845e-01, -8.8180e-02, -4.8942e-02,\n",
      "        -6.5044e-02,  1.6150e-02, -1.0052e-02, -9.2649e-02,  1.0386e-01,\n",
      "        -7.0843e-02, -8.1365e-02, -1.7094e-01, -4.9273e-02,  4.8591e-02,\n",
      "         3.9547e-02, -1.7217e-01, -1.2449e-01,  4.5547e-02, -7.6044e-02,\n",
      "        -4.2473e-02,  1.7144e-02, -3.0190e-02,  2.2441e-02, -5.5689e-02,\n",
      "         1.2941e-01, -2.0618e-01, -2.3864e-02,  1.1493e-01,  5.4762e-03,\n",
      "         1.2021e-01,  1.6233e-01, -9.8754e-02, -9.4680e-02, -2.0533e-02,\n",
      "        -1.6358e-01,  2.1310e-02,  5.3418e-02, -1.0510e-01, -9.8039e-02,\n",
      "        -2.0404e-01, -1.4481e-01,  4.8784e-02, -7.9090e-02, -2.3430e-01,\n",
      "         7.8879e-02, -9.0319e-03,  2.8341e-02,  1.8541e-01, -9.4816e-02,\n",
      "        -1.5203e-01,  1.0471e-01, -4.4634e-02,  8.7537e-02, -2.3622e-01,\n",
      "         8.7137e-03,  8.7376e-02, -2.5655e-02, -5.7541e-02, -1.1855e-01,\n",
      "        -7.1249e-02,  2.6345e-01, -1.6200e-01,  7.8575e-02,  1.2093e-01,\n",
      "        -6.2786e-02,  1.3455e-02, -1.3915e-01, -1.3287e-01, -4.1340e-02,\n",
      "        -2.9712e-02,  6.8530e-02,  4.1473e-02,  1.0792e-02,  1.1580e-01,\n",
      "         1.6040e-02, -6.6376e-02,  9.0783e-02, -1.9302e-01, -1.2595e-01,\n",
      "         1.6401e-01, -2.2630e-01,  2.0197e-01, -1.0451e-01, -7.3036e-03,\n",
      "         2.1508e-01, -1.5724e-01, -2.9916e-02, -6.8131e-02, -9.9106e-02,\n",
      "         1.1909e-02, -1.1361e-01, -9.0919e-03, -1.6789e-01,  5.0626e-02,\n",
      "        -6.6700e-02, -2.8661e-03, -1.7900e-01,  9.8013e-02,  7.5663e-02,\n",
      "        -9.6130e-02, -1.4669e-01, -1.3623e-02, -1.4996e-01, -1.2412e-01,\n",
      "        -1.0415e-01,  9.7367e-02, -4.8191e-02,  1.2200e-02, -2.1325e-02,\n",
      "        -6.3338e-02, -2.3686e-02,  5.1068e-02, -9.9109e-02, -2.6353e-01,\n",
      "         9.7003e-02,  1.9832e-02,  9.4267e-02, -1.2570e-01, -1.9939e-01,\n",
      "        -9.7705e-02,  1.2374e-01,  3.0204e-03, -2.1773e-01, -1.8367e-02,\n",
      "         3.6884e-02,  3.0758e-02, -5.4645e-02, -6.4589e-02, -2.2755e-02,\n",
      "        -4.3250e-02, -2.6158e-02, -1.6842e-01,  5.7254e-02, -1.0729e-01,\n",
      "        -2.0724e-01, -3.2570e-02, -8.6110e-02, -1.2743e-01,  2.2671e-01,\n",
      "         4.4365e-02,  5.7137e-02,  6.2411e-02, -1.9190e-01, -4.5171e-02,\n",
      "        -1.2872e-01, -2.0059e-02,  1.6715e-01, -1.0513e-01,  1.3336e-01,\n",
      "        -5.5786e-03, -1.2118e-02,  1.5986e-02,  7.7987e-02,  2.0544e-02,\n",
      "         1.4466e-01, -1.6794e-01, -8.3093e-03, -1.5368e-01, -2.2352e-02,\n",
      "        -5.2955e-02, -8.2078e-02, -1.0886e-02, -8.1486e-03, -8.0602e-02,\n",
      "         1.8340e-01,  3.0239e-03, -1.0677e-01, -2.3769e-01, -8.0020e-02,\n",
      "         8.0256e-02, -5.3057e-02, -7.4351e-02,  7.5900e-02, -1.7286e-01,\n",
      "         1.3108e-01,  1.1935e-01, -5.8390e-02,  8.1472e-02,  2.4423e-02,\n",
      "         4.5493e-02, -5.2935e-02, -1.4730e-01, -5.5582e-02, -1.3871e-01,\n",
      "        -6.5200e-02, -7.1990e-02,  1.6912e-01, -4.7424e-02,  5.8069e-02,\n",
      "        -8.4316e-03, -4.3105e-02,  1.9739e-02,  1.2257e-01,  1.6149e-01,\n",
      "         7.8939e-03, -9.1276e-02,  1.3371e-01, -3.8045e-02, -1.1052e-01,\n",
      "         3.1865e-02, -2.6667e-02, -7.9539e-02,  1.5467e-01, -1.1664e-01,\n",
      "        -2.1853e-02, -1.6105e-02, -8.1431e-02,  7.2876e-02, -1.2175e-01,\n",
      "        -5.7691e-03, -2.4484e-02,  4.9558e-02, -6.9120e-02, -9.2244e-02,\n",
      "        -2.6927e-01, -9.1400e-02, -9.2389e-02, -2.2788e-01,  1.2807e-01,\n",
      "         1.5642e-02, -1.1052e-01, -1.9767e-01,  6.1648e-02, -1.7682e-01,\n",
      "         3.6117e-02,  4.3703e-02, -1.0836e-03, -3.7995e-02, -6.9334e-02,\n",
      "         1.4921e-01,  1.7902e-02, -1.3042e-01, -1.3328e-01,  9.9664e-02,\n",
      "        -3.7860e-02,  1.0932e-01,  1.5740e-01,  1.1964e-01,  9.0147e-02,\n",
      "         8.4790e-02, -3.6848e-02,  1.1207e-01, -1.2765e-01, -8.7493e-02,\n",
      "        -2.2044e-04, -1.4963e-01,  9.8051e-02, -4.0717e-02, -2.2872e-02,\n",
      "        -1.8534e-01, -4.0249e-02, -1.3070e-01, -3.2632e-02,  7.0838e-02,\n",
      "        -6.8076e-02,  7.8552e-02,  9.1595e-02, -2.1460e-01, -1.0673e-01,\n",
      "         8.4080e-02, -1.4631e-01, -2.0025e-01, -7.6874e-03,  1.7984e-01,\n",
      "        -3.0008e-01, -1.6763e-01, -7.3247e-02, -3.6976e-03, -1.8174e-02,\n",
      "        -1.6280e-01, -6.5587e-02, -2.0051e-02, -1.2982e-01, -1.8824e-01,\n",
      "         8.4438e-02,  3.6681e-02,  1.1793e-01,  1.4802e-01, -1.0467e-01,\n",
      "         1.5770e-02, -9.5090e-02,  5.6617e-02,  9.3301e-03,  5.9373e-02,\n",
      "         1.3184e-02, -4.9973e-02, -2.8606e-02, -2.3735e-01, -5.5076e-02,\n",
      "         1.0926e-01, -2.3208e-01, -1.0507e-02, -2.4228e-01, -2.0315e-01,\n",
      "        -7.0127e-02,  8.5857e-02,  4.2245e-02,  3.3120e-02, -1.2450e-01,\n",
      "        -6.2689e-02, -2.0222e-01, -1.2036e-01, -2.9883e-02, -1.0234e-01,\n",
      "         1.2956e-01, -7.7425e-03,  2.3763e-02,  1.4837e-01,  8.1435e-02,\n",
      "        -2.7519e-01, -2.1893e-01,  4.7514e-02, -9.1513e-02, -1.7287e-01,\n",
      "        -2.1948e-01, -1.8447e-01,  4.3664e-02,  5.3203e-02,  6.5925e-02,\n",
      "         6.8502e-02, -2.7233e-01, -4.1554e-02, -3.4285e-03, -1.0254e-01,\n",
      "        -1.0606e-01, -1.4967e-01, -2.7546e-01,  4.1412e-02,  1.0572e-01,\n",
      "        -4.3329e-02, -1.0534e-01, -7.1884e-02, -3.1268e-02, -1.1429e-01,\n",
      "         4.4573e-02, -8.9595e-02,  7.6953e-02,  1.0093e-01, -3.9810e-02,\n",
      "         1.6395e-01,  1.5607e-01,  1.5446e-02,  1.1743e-01,  3.7378e-02,\n",
      "        -2.1721e-01, -7.2714e-02,  6.6318e-03, -5.0213e-02, -2.3937e-02,\n",
      "        -8.7232e-02, -7.4201e-02, -1.2579e-01, -2.5464e-01, -2.0099e-02,\n",
      "         8.4452e-02,  9.3981e-02, -1.4457e-01, -6.8108e-02,  2.0369e-02,\n",
      "        -1.7091e-01, -5.4359e-02, -2.3891e-02, -9.5876e-02,  8.7637e-02,\n",
      "        -7.2353e-02, -5.6242e-02,  8.4319e-02, -3.8211e-02,  2.6649e-02,\n",
      "         3.8608e-02,  3.9643e-02, -9.0685e-02, -1.0442e-02, -1.6577e-01,\n",
      "        -1.1807e-01, -6.4445e-02, -1.6190e-01, -1.0863e-01, -3.2580e-02,\n",
      "        -1.6447e-01, -1.3991e-01, -4.9212e-02,  1.2105e-01, -1.2753e-01,\n",
      "        -1.8391e-02,  9.0894e-02, -1.9985e-01, -6.3306e-02,  5.3169e-02,\n",
      "        -1.3013e-01,  1.0998e-01,  9.6600e-02, -9.7795e-02,  1.5285e-01,\n",
      "        -1.3423e-01, -3.2070e-02, -7.3072e-02,  2.5401e-02, -4.5248e-02,\n",
      "        -4.2676e-02, -1.3588e-01, -7.9658e-02,  1.2994e-01,  6.9070e-02,\n",
      "         1.0215e-01, -1.0551e-01, -1.7226e-01,  7.4783e-02, -1.8119e-01,\n",
      "         2.9299e-02, -7.5109e-02, -7.8027e-02, -3.2709e-02,  1.4061e-01,\n",
      "        -2.6523e-02,  1.4277e-01, -8.8922e-02, -8.9133e-02, -1.4875e-01,\n",
      "        -8.0697e-02,  2.5719e-02, -1.2073e-01, -4.1648e-03,  2.0196e-01,\n",
      "        -6.3123e-02,  4.4631e-02, -9.2128e-02,  1.4439e-01, -9.6463e-02,\n",
      "        -9.6011e-02, -1.1094e-01,  1.2064e-01,  1.8113e-01, -2.3285e-01,\n",
      "        -1.1232e-01, -5.4221e-02, -3.9257e-02,  9.0039e-02, -3.8251e-02,\n",
      "         5.2979e-02,  6.6742e-02, -2.6412e-01,  7.8769e-02, -1.9013e-01,\n",
      "         5.2828e-02, -5.1443e-02, -4.9837e-02, -6.0307e-02, -1.1562e-01,\n",
      "        -3.4097e-02,  6.2978e-02,  2.9051e-03,  1.4385e-01, -1.0267e-01,\n",
      "        -9.4014e-02, -1.1969e-01, -5.4565e-02,  8.2935e-05,  8.6551e-02,\n",
      "         1.1081e-01,  1.2692e-02,  1.6172e-02,  3.3343e-02, -3.6463e-02,\n",
      "        -9.6313e-02, -2.5214e-02, -3.8218e-03, -8.8738e-02, -7.3742e-02,\n",
      "         7.8396e-02, -2.1549e-01,  4.4939e-02,  1.6170e-01, -9.6667e-02,\n",
      "        -1.1850e-01,  3.0484e-02, -7.0804e-02, -1.6510e-02,  9.8144e-02,\n",
      "        -1.8414e-01,  1.2626e-02, -1.2601e-02, -1.4195e-01, -1.5035e-01,\n",
      "        -1.3922e-01, -2.5891e-01, -2.7859e-01, -1.2398e-01,  1.1808e-01,\n",
      "        -1.9352e-01, -3.6115e-02, -1.2099e-02, -8.8274e-02,  1.0010e-02,\n",
      "        -1.2754e-01, -8.8858e-02,  1.2657e-02, -2.0754e-02, -1.1072e-01,\n",
      "         2.2840e-01, -1.8411e-02, -1.9162e-02,  5.4521e-02,  5.8150e-02,\n",
      "         8.1518e-02, -1.9590e-01,  1.5646e-01, -1.3377e-01,  1.4462e-01,\n",
      "        -5.3366e-03, -1.5828e-01,  5.1011e-02, -1.8956e-01,  4.8139e-02,\n",
      "         4.1431e-02, -1.9670e-01, -1.9129e-01, -1.3670e-02, -2.6059e-02,\n",
      "        -3.2586e-02, -5.5371e-02,  1.1547e-01, -2.2537e-01,  6.8702e-02,\n",
      "        -2.7272e-01, -3.4503e-02,  9.7579e-02, -5.4886e-02, -2.3335e-01,\n",
      "         8.7605e-02,  8.9711e-02, -7.5154e-02,  1.5698e-01,  5.9540e-03,\n",
      "        -6.3895e-02,  3.7949e-02, -2.3378e-02, -8.1383e-02,  1.5255e-01,\n",
      "        -4.9470e-02,  1.2247e-01,  1.3474e-01, -7.1603e-02, -2.9665e-02,\n",
      "        -1.3031e-01, -1.1455e-01, -5.0046e-02, -9.2476e-02, -6.7936e-02,\n",
      "        -1.5037e-01,  6.8416e-02, -1.5420e-03, -1.5098e-02,  5.2158e-02,\n",
      "         3.6365e-02,  1.2385e-01,  8.0279e-02, -8.0517e-02, -8.8063e-02,\n",
      "         4.6207e-02, -1.7698e-02,  1.3948e-01, -1.2896e-01,  1.8322e-01,\n",
      "         7.5652e-02, -1.9066e-01, -1.1900e-01, -1.3123e-01, -1.3908e-01,\n",
      "        -1.6684e-01,  1.1738e-01,  1.3230e-02, -6.3393e-02, -5.9263e-03,\n",
      "         6.2213e-02, -5.3039e-02,  7.2736e-02, -1.6199e-01, -3.5195e-02,\n",
      "        -1.5489e-01, -9.2616e-02, -2.6300e-01, -6.8079e-02, -1.3927e-01,\n",
      "         1.4529e-02,  9.8603e-03, -1.7225e-01,  1.9905e-01,  5.7790e-02,\n",
      "        -3.2355e-02, -7.5093e-02,  3.9543e-02, -2.1125e-01,  3.3468e-02,\n",
      "         1.1410e-01, -1.1604e-01, -1.8598e-01, -1.6455e-01, -1.5880e-01,\n",
      "         1.3934e-01,  1.8042e-02, -8.9940e-02,  6.0694e-02, -1.9152e-01,\n",
      "         1.2775e-01,  4.3798e-02, -6.3290e-02,  1.1626e-01, -2.3056e-01,\n",
      "        -1.1210e-01, -1.7880e-01, -6.6762e-02,  4.2403e-02,  2.2489e-02],\n",
      "       requires_grad=True)\n",
      "linear2.weight :  Parameter containing:\n",
      "tensor([[-5.3205e-02,  1.3372e-02,  2.2431e-02,  ...,  2.7418e-02,\n",
      "          2.4944e-02,  2.0347e-02],\n",
      "        [ 1.0857e-02, -3.0795e-02,  1.8991e-03,  ..., -2.3494e-02,\n",
      "         -9.2988e-04, -2.9925e-02],\n",
      "        [-5.5939e-02, -2.9921e-02,  8.9242e-03,  ...,  3.7337e-03,\n",
      "          2.8744e-02, -4.4133e-02],\n",
      "        ...,\n",
      "        [-3.2241e-02,  1.8989e-03,  7.6400e-03,  ...,  1.3270e-02,\n",
      "          2.9887e-03, -2.5214e-02],\n",
      "        [ 1.0098e-04, -1.3864e-01,  7.0583e-03,  ..., -2.8063e-02,\n",
      "          2.8585e-02, -3.9881e-03],\n",
      "        [ 1.0344e-02, -1.0141e-03,  1.9483e-02,  ...,  6.5575e-03,\n",
      "         -2.3820e-02, -9.5261e-03]], requires_grad=True)\n",
      "linear2.bias :  Parameter containing:\n",
      "tensor([-3.1227e-02, -1.2063e-01, -8.7593e-02,  9.0753e-03, -6.5903e-02,\n",
      "         2.0395e-02,  1.5856e-02, -5.3575e-02,  4.4587e-03, -5.1796e-03,\n",
      "        -1.2370e-02, -1.7533e-02, -1.3573e-01, -5.4383e-02,  1.5351e-02,\n",
      "         5.7181e-02,  3.5518e-02,  5.1090e-03, -1.2852e-01, -7.7403e-03,\n",
      "         2.8477e-02, -3.3822e-02, -4.6584e-02,  1.3721e-02, -3.6057e-02,\n",
      "        -1.1196e-01, -1.5169e-02, -8.0198e-02,  8.7892e-03,  6.5334e-02,\n",
      "        -8.9734e-03,  3.9425e-02, -1.2523e-01,  2.3476e-03, -1.0798e-02,\n",
      "        -3.5918e-02,  4.3753e-03, -3.7655e-02,  1.0004e-02, -1.3138e-02,\n",
      "        -4.1863e-02, -9.6234e-02,  7.1377e-03, -1.4133e-02, -1.2702e-01,\n",
      "        -9.7002e-02, -1.9086e-02,  2.6162e-02, -3.1632e-02,  7.2581e-03,\n",
      "        -9.3315e-03, -1.0177e-01, -1.0387e-01,  5.2387e-02,  1.7791e-02,\n",
      "        -6.8981e-02, -3.7177e-02, -6.0024e-03,  7.5067e-02,  9.8008e-02,\n",
      "         1.3951e-02,  3.9353e-02, -7.3505e-02,  3.4111e-02, -1.6124e-01,\n",
      "         2.8152e-02,  1.0884e-02,  3.4531e-02, -1.3965e-01,  3.5785e-02,\n",
      "        -1.3735e-02, -1.4234e-01,  2.4439e-02,  8.4305e-02,  1.0453e-02,\n",
      "        -1.3890e-03, -4.3713e-02, -1.5332e-02, -3.4701e-02, -1.6581e-02,\n",
      "        -8.9905e-02, -3.3250e-02,  1.8197e-02, -1.3398e-01,  2.5827e-03,\n",
      "        -8.3828e-02,  2.0053e-03, -1.3132e-01,  1.4258e-01, -3.0969e-02,\n",
      "        -3.7232e-04,  3.6584e-03,  7.6612e-02,  1.5297e-02, -4.0092e-02,\n",
      "        -3.0389e-02,  3.0834e-02,  1.1981e-01,  4.9059e-02,  1.5232e-02,\n",
      "         5.5365e-02, -1.0461e-01, -1.3920e-02, -2.6410e-02,  3.9982e-02,\n",
      "         1.5604e-02,  1.2822e-02, -3.7172e-02, -9.6761e-02,  2.8280e-02,\n",
      "        -1.7845e-02,  5.0919e-02, -5.0519e-02,  1.5736e-02,  2.8622e-03,\n",
      "        -7.7360e-03,  1.5813e-02, -3.4738e-02, -2.8455e-02,  1.0894e-02,\n",
      "        -6.1238e-02, -5.2709e-02, -2.3342e-02,  1.6050e-02,  7.3428e-02,\n",
      "        -2.6007e-03,  2.1443e-02,  4.5603e-03, -8.6801e-03,  3.0922e-02,\n",
      "        -4.7450e-02, -2.3398e-03, -1.3609e-02, -6.9705e-03, -8.4434e-03,\n",
      "        -1.1632e-01, -1.1087e-01,  5.2103e-02, -1.0210e-02, -9.5030e-02,\n",
      "        -2.3930e-02,  1.1877e-03,  5.4541e-02, -2.0686e-02, -2.4445e-02,\n",
      "        -2.2546e-02, -6.8781e-03, -5.2037e-02, -1.5753e-02, -1.1442e-01,\n",
      "        -1.7838e-02,  5.4861e-02, -4.2932e-02, -8.2574e-03, -1.2258e-02,\n",
      "        -4.6129e-02,  1.2836e-01, -2.5296e-02, -1.7273e-02, -2.4066e-02,\n",
      "        -1.3581e-02, -1.1532e-02, -1.5898e-02,  3.5124e-02, -9.8878e-03,\n",
      "        -1.8007e-02, -2.1136e-02, -8.1905e-02, -2.3799e-02, -1.3706e-01,\n",
      "         3.1471e-02, -1.9479e-02, -4.1077e-02, -3.7159e-02, -5.7094e-03,\n",
      "        -3.1559e-02, -9.7518e-02, -1.0030e-02,  2.1129e-02, -1.2576e-01,\n",
      "        -1.4195e-01, -1.3186e-02, -4.1847e-03,  2.8914e-02, -1.3763e-01,\n",
      "        -2.5078e-02, -2.4455e-02, -1.2533e-01, -5.0751e-03, -1.3313e-01,\n",
      "         1.1544e-02, -7.3833e-03, -1.0535e-01, -3.1108e-03,  6.7022e-02,\n",
      "        -3.3256e-03,  7.7434e-02, -1.8203e-02, -2.7233e-02,  1.6513e-02,\n",
      "         2.1114e-02,  1.7052e-02, -2.6543e-02, -3.7277e-02, -4.4631e-02,\n",
      "         2.1392e-02, -3.2703e-02, -7.9118e-03, -2.6118e-02,  3.1387e-02,\n",
      "        -2.9109e-02,  2.5941e-02,  1.2636e-02,  2.5027e-02, -1.1799e-01,\n",
      "        -1.4844e-02, -7.6866e-02, -1.3495e-02,  6.2529e-03, -2.3228e-02,\n",
      "        -3.3485e-02,  8.4312e-03,  3.7319e-03,  7.6432e-03,  5.9455e-02,\n",
      "        -7.4713e-02, -6.7346e-02, -8.6093e-03, -1.0259e-01, -1.6541e-01,\n",
      "        -1.5091e-01, -3.8803e-02, -1.3781e-01,  3.4585e-02, -1.1570e-01,\n",
      "        -2.7454e-03, -3.1678e-02,  2.0803e-02,  1.7976e-02,  5.0271e-02,\n",
      "         1.1124e-01, -6.5365e-02, -1.3689e-01,  2.0051e-02,  4.9502e-02,\n",
      "         1.3022e-02,  1.3995e-02, -3.4190e-02, -8.9580e-03, -2.5965e-02,\n",
      "        -4.8402e-02, -4.1672e-02, -5.9196e-02,  4.9778e-02, -8.9519e-02,\n",
      "        -4.2232e-02,  4.5261e-04, -9.9525e-03, -2.5347e-02,  1.9619e-02,\n",
      "        -1.2506e-01, -4.3938e-02, -2.1604e-02, -1.3892e-02, -1.6487e-01,\n",
      "        -6.7053e-02, -3.4973e-02,  1.3218e-02, -9.6325e-02,  2.1371e-02,\n",
      "         7.4940e-03, -5.3141e-02,  3.8069e-02,  1.4277e-03, -2.8122e-03,\n",
      "         1.6001e-02,  1.8639e-02, -6.8285e-02,  3.0314e-03,  5.6714e-02,\n",
      "         5.3678e-02,  3.0436e-02, -3.3175e-02,  8.2755e-03, -3.1200e-02,\n",
      "         2.2729e-02, -6.3083e-02, -6.6257e-02,  1.4012e-02,  9.8983e-02,\n",
      "        -1.3519e-01,  2.4580e-02, -1.9696e-03, -1.8195e-02,  6.4969e-03,\n",
      "        -6.5597e-02, -7.4716e-02,  4.8491e-02, -2.6958e-02,  1.0132e-02,\n",
      "        -4.9998e-02, -3.8775e-02,  3.8376e-02,  3.9789e-03, -3.7932e-02,\n",
      "        -1.1649e-01, -8.6473e-02, -4.2534e-02,  1.5659e-02, -1.1243e-01,\n",
      "        -5.1931e-02, -6.9427e-02, -2.7012e-02, -3.7574e-02, -3.8715e-03,\n",
      "         9.9030e-03, -1.8080e-01,  1.4865e-02,  2.3968e-03, -3.1825e-02,\n",
      "         1.0073e-02,  1.3304e-02, -2.8465e-02,  1.9574e-02, -3.4906e-02,\n",
      "        -3.4475e-03, -1.3778e-01, -1.1813e-01,  2.6259e-02, -1.3273e-01,\n",
      "        -4.1464e-02, -2.2476e-03,  2.6359e-02,  5.6271e-02, -1.1767e-02,\n",
      "        -3.8211e-02, -7.0311e-02,  4.7225e-02, -4.9893e-02,  5.9444e-02,\n",
      "         2.5146e-02, -1.2391e-01,  4.0768e-02,  7.1269e-02, -3.6671e-02,\n",
      "        -3.4153e-03,  1.4598e-02, -3.4263e-02, -1.7420e-04, -9.4337e-02,\n",
      "         1.6313e-03,  2.7850e-02, -5.7647e-02,  1.4421e-02, -3.7812e-02,\n",
      "         4.5987e-02,  6.3658e-02,  2.3472e-02,  6.8118e-02, -1.0363e-03,\n",
      "        -1.8959e-02, -1.8065e-02, -6.7351e-02, -1.3352e-01, -1.0612e-01,\n",
      "         1.6942e-02,  6.2133e-03,  7.8169e-02,  1.6148e-02,  2.1391e-03,\n",
      "         3.8228e-03,  1.3951e-02,  2.4923e-02, -4.4455e-03, -2.2035e-02,\n",
      "        -1.4133e-01,  3.8069e-02,  3.1448e-02,  9.4016e-03, -3.4615e-02,\n",
      "         4.1253e-02, -1.4931e-02, -2.3362e-02,  5.1631e-02,  6.3156e-02,\n",
      "         9.6024e-04, -6.0947e-03, -5.7448e-02, -7.4893e-02, -1.4333e-01,\n",
      "         9.7248e-03, -3.7338e-02, -1.1534e-01, -1.0225e-01,  4.4261e-02,\n",
      "        -6.8738e-03, -4.3753e-02, -3.1708e-02, -2.1128e-02,  7.8725e-02,\n",
      "        -2.2739e-02, -7.4636e-02, -9.0704e-02,  3.8956e-02,  4.0538e-02,\n",
      "         1.4257e-02, -1.3481e-01, -1.6812e-02,  5.2227e-02, -4.0649e-02,\n",
      "        -3.1998e-02, -3.8563e-02, -2.7116e-02,  3.0143e-02, -1.0800e-02,\n",
      "         8.4146e-03,  1.6393e-03,  7.5406e-03, -1.3794e-01, -3.5051e-02,\n",
      "         4.7196e-02,  5.6336e-02,  2.3467e-02,  1.4630e-02, -6.2719e-02,\n",
      "         3.8918e-02,  1.2945e-01, -3.4969e-02, -9.1257e-02, -4.2019e-02,\n",
      "         9.7858e-03, -8.6567e-03,  7.9286e-03, -1.5113e-02,  4.3414e-02,\n",
      "        -3.7841e-03,  1.9610e-02,  1.2829e-02, -5.9978e-03, -1.1026e-02,\n",
      "        -4.0845e-03,  1.7182e-02, -1.2492e-01, -4.4842e-02, -6.9449e-02,\n",
      "        -4.1449e-02,  3.4015e-02, -3.5683e-03, -1.4900e-02, -3.1046e-02,\n",
      "        -5.0382e-03,  1.8533e-02,  3.7644e-02,  8.1135e-03, -2.1093e-02,\n",
      "        -5.8416e-03,  7.6498e-02,  4.1104e-03, -4.9492e-03,  8.6411e-02,\n",
      "         3.4154e-02, -6.2131e-03,  1.6595e-02,  5.1063e-02, -6.2354e-02,\n",
      "         4.0835e-03, -5.3949e-02, -5.0767e-02, -2.4900e-02, -1.1165e-01,\n",
      "         9.8879e-03, -3.6234e-02, -3.9114e-02, -3.8415e-02, -2.6277e-02,\n",
      "        -9.3583e-03, -8.3665e-02,  7.3198e-02,  7.2530e-03, -1.2960e-02,\n",
      "        -8.8998e-02,  1.8835e-02, -9.0223e-03, -3.6173e-03, -3.9365e-02,\n",
      "         9.6535e-02, -2.7956e-02, -1.2334e-01,  1.7986e-02, -2.0433e-01,\n",
      "        -8.9550e-03,  3.4318e-02,  4.4034e-02, -7.6198e-02, -2.8661e-03,\n",
      "        -3.8644e-02,  1.0879e-01,  1.9625e-02, -1.8788e-01,  6.1637e-02],\n",
      "       requires_grad=True)\n",
      "linear3.weight :  Parameter containing:\n",
      "tensor([[-0.0570,  0.0330,  0.0356,  ..., -0.0013,  0.0286,  0.0137],\n",
      "        [-0.0262, -0.0388,  0.0365,  ..., -0.0199, -0.0092, -0.0945],\n",
      "        [ 0.0256, -0.0356, -0.0102,  ...,  0.0109, -0.0436, -0.0050],\n",
      "        ...,\n",
      "        [-0.0626, -0.0369, -0.0179,  ..., -0.0262,  0.0329, -0.0619],\n",
      "        [ 0.0075, -0.0256,  0.0310,  ..., -0.0212, -0.0154, -0.0207],\n",
      "        [-0.0024,  0.0450,  0.0462,  ...,  0.0333, -0.0506, -0.0335]],\n",
      "       requires_grad=True)\n",
      "linear3.bias :  Parameter containing:\n",
      "tensor([ 0.0249,  0.0082,  0.0584, -0.0136, -0.0346, -0.0346, -0.0716, -0.0089,\n",
      "         0.0457,  0.0201,  0.0483, -0.0490, -0.0358, -0.0076, -0.0995, -0.0321,\n",
      "         0.0248, -0.0098, -0.0285, -0.0701, -0.0083,  0.0493,  0.0063, -0.0295,\n",
      "        -0.0343,  0.0312,  0.0247,  0.0140,  0.0073, -0.0253, -0.0308, -0.0390,\n",
      "        -0.0064,  0.0572, -0.0241,  0.0239,  0.0233, -0.0996,  0.0216,  0.0037,\n",
      "         0.0569, -0.0248, -0.0491, -0.0258, -0.0630,  0.0750,  0.0407, -0.0565,\n",
      "        -0.0559, -0.0345], requires_grad=True)\n",
      "linear4.weight :  Parameter containing:\n",
      "tensor([[ 0.0004,  0.0384,  0.1240,  0.0879,  0.1095, -0.0535,  0.0551, -0.1127,\n",
      "         -0.0612,  0.0985,  0.1768,  0.0448,  0.0709,  0.1022,  0.1154, -0.1094,\n",
      "          0.1387, -0.0515, -0.0257, -0.0134,  0.0755,  0.1262, -0.1582,  0.0320,\n",
      "          0.0143,  0.1719,  0.0181, -0.0565, -0.0747,  0.1700,  0.1244,  0.0301,\n",
      "         -0.1607,  0.0344,  0.0241,  0.0321,  0.0661,  0.0254, -0.0220,  0.1463,\n",
      "         -0.0959, -0.1301, -0.0994, -0.0876, -0.0117,  0.0882, -0.0509,  0.0299,\n",
      "          0.0239, -0.1290],\n",
      "        [-0.0866, -0.0142, -0.0431,  0.0586, -0.0767, -0.0894,  0.0864,  0.0179,\n",
      "         -0.0272, -0.0890,  0.0867, -0.0706, -0.0218, -0.0728, -0.0529,  0.0088,\n",
      "         -0.0974,  0.0606, -0.0713,  0.0290, -0.1218, -0.1299, -0.1740,  0.0510,\n",
      "         -0.0032, -0.1290,  0.0878,  0.0876, -0.1030,  0.0337,  0.0364, -0.0792,\n",
      "         -0.1890, -0.1270,  0.1293, -0.0286,  0.0950,  0.0343, -0.0946, -0.1054,\n",
      "         -0.0383,  0.0058,  0.0644, -0.0608, -0.1923,  0.1093, -0.0516, -0.0871,\n",
      "          0.0731,  0.0461],\n",
      "        [-0.0742, -0.1472,  0.0175,  0.0309, -0.1303, -0.0304, -0.0634, -0.0505,\n",
      "          0.1017, -0.1409,  0.0854,  0.0652, -0.1565, -0.0361,  0.0788,  0.1039,\n",
      "         -0.0380, -0.0623,  0.0254,  0.0607,  0.1435, -0.0638,  0.0149,  0.1697,\n",
      "          0.1221,  0.1957, -0.1198,  0.1287, -0.0252, -0.0760,  0.1368,  0.0161,\n",
      "         -0.1097, -0.1405,  0.1162,  0.0496,  0.0877, -0.0038, -0.1098, -0.0888,\n",
      "          0.1478,  0.0596,  0.0557, -0.0118,  0.0824, -0.0116, -0.1152, -0.0991,\n",
      "          0.1358, -0.1014],\n",
      "        [-0.0021, -0.1229,  0.0805, -0.0988,  0.0126,  0.0838, -0.0630, -0.0907,\n",
      "         -0.1022, -0.0627,  0.1367,  0.0920, -0.0009, -0.0315, -0.0849,  0.1047,\n",
      "          0.0196,  0.0259,  0.0364, -0.0798,  0.0563,  0.1408,  0.1811, -0.1030,\n",
      "         -0.0825,  0.0394,  0.0575, -0.1727, -0.1247,  0.0682, -0.1014,  0.0564,\n",
      "         -0.0025, -0.1735,  0.1563, -0.0822,  0.0334, -0.1724, -0.0099,  0.1611,\n",
      "         -0.0730, -0.0027,  0.0052,  0.0884,  0.0206, -0.0592,  0.1692,  0.0227,\n",
      "         -0.1218,  0.0332],\n",
      "        [ 0.0496,  0.0062, -0.0947, -0.0325, -0.0056,  0.0629,  0.0351, -0.0276,\n",
      "          0.0737,  0.0857,  0.0130, -0.0046, -0.2120,  0.0436, -0.0635, -0.0413,\n",
      "          0.0802,  0.0950, -0.0683,  0.0223, -0.0500, -0.0238, -0.1614,  0.0380,\n",
      "         -0.1006, -0.0693,  0.0756,  0.0606, -0.0545, -0.0513, -0.0824,  0.0748,\n",
      "          0.1287, -0.0218,  0.0043, -0.1241,  0.0004,  0.1279,  0.1248, -0.0346,\n",
      "          0.0611,  0.0903,  0.0385, -0.0261,  0.0816,  0.0898,  0.0373,  0.0892,\n",
      "         -0.0331, -0.1237]], requires_grad=True)\n",
      "linear4.bias :  Parameter containing:\n",
      "tensor([-0.0505, -0.0098, -0.0378, -0.1643,  0.0460], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for name,values in feature_extractor.named_parameters():\n",
    "    print(name,\": \", values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdditiveWithProjectionGP(gpytorch.models.ExactGP):\n",
    "    def __init__(self, X_train, y_train, likelihood, d, max_degree):\n",
    "        super().__init__(X_train, y_train, likelihood)\n",
    "\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.NewtonGirardAdditiveKernel(\n",
    "            RBFKernel(ard_num_dims=d), \n",
    "            # gpytorch.kernels.GridInterpolationKernel(\n",
    "            #     gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(ard_num_dims=d)),\n",
    "            #     num_dims=d, grid_size=100),\n",
    "            # d, \n",
    "            max_degree,\n",
    "        )\n",
    "            \n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.scale_to_bounds = gpytorch.utils.grid.ScaleToBounds(-1., 1.) # This module will scale the NN features so that they're nice values\n",
    "        self.max_degree = max_degree\n",
    "\n",
    "    def forward(self, X):\n",
    "        projected_X = self.feature_extractor(X)\n",
    "        projected_X = self.scale_to_bounds(projected_X)  # Make the NN values \"nice\"\n",
    "\n",
    "        mean = self.mean_module(projected_X)\n",
    "        covar = self.covar_module(projected_X)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean, covar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [03:08<00:00,  1.59it/s]\n"
     ]
    }
   ],
   "source": [
    "likelihood = GaussianLikelihood()\n",
    "max_degree = proj_dim   # if 1, it's GAM, and it's has already been done...\n",
    "model = AdditiveWithProjectionGP(to_torch(X_train),to_torch(y_train),likelihood,proj_dim,max_degree)\n",
    "\n",
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': model.feature_extractor.parameters()},\n",
    "    {'params': model.covar_module.parameters()},\n",
    "    {'params': model.mean_module.parameters()},\n",
    "    {'params': model.likelihood.parameters()},\n",
    "], lr=0.01)\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "training_iterations = 300\n",
    "loss_vals = []\n",
    "# iterator = tqdm.notebook.tqdm(range(training_iterations))\n",
    "for i in tqdm(range(training_iterations)):\n",
    "    # Zero backprop gradients\n",
    "    optimizer.zero_grad()\n",
    "    # Get output from model\n",
    "    output = model(to_torch(X_train))\n",
    "    # Calc loss and backprop derivatives\n",
    "    loss = -mll(output, to_torch(y_train))\n",
    "    loss.backward()\n",
    "    # iterator.set_postfix(loss=loss.item())\n",
    "    optimizer.step()\n",
    "    loss_vals.append(loss.item())\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x33f4d46d0>]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.06912349\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "        preds = likelihood(model(to_torch(X_test)))\n",
    "\n",
    "print(\n",
    "    #     negative_log_predictive_density(preds, to_torch(y_test)).numpy(), \n",
    "    #   mean_standardized_log_loss(preds,to_torch(y_test)).numpy(),\n",
    "      )\n",
    "print(np.sqrt(mean_squared_error(preds,to_torch(y_test)).numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# likelihood = GaussianLikelihood()\n",
    "# model = AdditiveWithProjectionGP(to_torch(X_train),to_torch(y_train),likelihood,proj_dim,max_degree)\n",
    "# for param_name, param in model.named_parameters():\n",
    "#     print(f'Parameter name: {param_name:42} value = {param}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# likelihood = GaussianLikelihood()\n",
    "# model = AdditiveWithProjectionGP(to_torch(X_train),to_torch(y_train),likelihood,proj_dim,max_degree)\n",
    "# for param_name, param in model.named_parameters():\n",
    "#     print(f'Parameter name: {param_name:42} value = {param}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
